{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a83341",
   "metadata": {},
   "source": [
    "# Build mutliclass classification models where some use RFE selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d435b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)\n",
    "from sklearn.feature_selection import RFECV\n",
    "import random\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import svm, datasets\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a92679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first column of dataframe\n",
    "def drop_first_col(df):\n",
    "    return df.iloc[: , 1:]\n",
    "\n",
    "X_train_20 = pd.read_csv(\"dataset\\X_train_3_20.csv\")\n",
    "X_test_20 = pd.read_csv(\"dataset\\X_test_3_20.csv\")\n",
    "y_train_20 = pd.read_csv(\"dataset\\y_train_3_20.csv\")\n",
    "y_test_20 = pd.read_csv(\"dataset\\y_test_3_20.csv\")\n",
    "\n",
    "X_train_40 = pd.read_csv(\"dataset\\X_train_3_40.csv\")\n",
    "X_test_40 = pd.read_csv(\"dataset\\X_test_3_40.csv\")\n",
    "y_train_40 = pd.read_csv(\"dataset\\y_train_3_40.csv\")\n",
    "y_test_40 = pd.read_csv(\"dataset\\y_test_3_40.csv\")\n",
    "\n",
    "X_train_20 = drop_first_col(X_train_20)\n",
    "X_test_20 = drop_first_col(X_test_20)\n",
    "y_train_20 = drop_first_col(y_train_20)\n",
    "y_test_20 = drop_first_col(y_test_20)\n",
    "\n",
    "X_train_40 = drop_first_col(X_train_40)\n",
    "X_test_40 = drop_first_col(X_test_40)\n",
    "y_train_40 = drop_first_col(y_train_40)\n",
    "y_test_40 = drop_first_col(y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c6482",
   "metadata": {},
   "source": [
    "## Test on single commonly used models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c80bba",
   "metadata": {},
   "source": [
    "### XGB Classifier (with no hyperparameters selection) for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc922337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_class(X_train, X_test, y_train, y_test,learning_rate, n_estimators, max_depth,min_child_weight, gamma, subsample, colsample_bytree, simple):\n",
    "    \n",
    "    if simple:\n",
    "        clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False,objective='multi:softproba')\n",
    "    else:\n",
    "        clf = xgb.XGBClassifier(learning_rate = learning_rate, n_estimators = int(n_estimators), max_depth = int(max_depth), \n",
    "                                min_child_weight = min_child_weight, gamma = gamma, subsample = subsample, \n",
    "                                colsample_bytree = colsample_bytree, seed = 24,eval_metric='mlogloss',use_label_encoder =False,objective='multi:softproba')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_predicted))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, y_predicted))\n",
    "    \n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    y_predicted = label_binarize(y_predicted, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"AUC =\",roc_auc)\n",
    "    \n",
    "    return clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c01f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.56      0.50         9\n",
      "           1       0.70      0.70      0.70        10\n",
      "           2       0.50      0.38      0.43         8\n",
      "\n",
      "    accuracy                           0.56        27\n",
      "   macro avg       0.55      0.54      0.54        27\n",
      "weighted avg       0.56      0.56      0.55        27\n",
      "\n",
      "Accuracy: 0.5555555555555556\n",
      "MCC = 0.3305699764271252\n",
      "AUC = {0: 0.6111111111111112, 1: 0.7617647058823529, 2: 0.6085526315789473}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.32      0.30        19\n",
      "           1       0.42      0.55      0.48        20\n",
      "           2       0.43      0.20      0.27        15\n",
      "\n",
      "    accuracy                           0.37        54\n",
      "   macro avg       0.38      0.36      0.35        54\n",
      "weighted avg       0.38      0.37      0.36        54\n",
      "\n",
      "Accuracy: 0.37037037037037035\n",
      "MCC = 0.03047125546029282\n",
      "AUC = {0: 0.44360902255639095, 1: 0.5544117647058824, 2: 0.5487179487179487}\n"
     ]
    }
   ],
   "source": [
    "XGBc_y_predicted_20 = XGB_class(X_train_20,X_test_20,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "XGBc_y_predicted_40 = XGB_class(X_train_40,X_test_40,y_train_40,y_test_40,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8885d3",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2de33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMc(X_train,X_test,y_train,y_test):\n",
    "    clf = svm.SVC(kernel='poly',probability=True).fit(X_train, y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)\n",
    "    sSVM_y_predicted = clf.predict_proba(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    \n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    y_predicted = label_binarize(preds, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"AUC =\",roc_auc)\n",
    "    \n",
    "    return sSVM_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c7d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.50         9\n",
      "           1       0.71      1.00      0.83        10\n",
      "           2       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.65      0.65      0.63        27\n",
      "weighted avg       0.65      0.67      0.64        27\n",
      "\n",
      "Accuracy: 0.6666666666666666\n",
      "MCC = 0.5046684724839113\n",
      "AUC = {0: 0.6388888888888888, 1: 0.8823529411764706, 2: 0.6973684210526315}\n",
      "Using 40% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.42      0.43        19\n",
      "           1       0.64      0.80      0.71        20\n",
      "           2       0.36      0.27      0.31        15\n",
      "\n",
      "    accuracy                           0.52        54\n",
      "   macro avg       0.48      0.50      0.48        54\n",
      "weighted avg       0.49      0.52      0.50        54\n",
      "\n",
      "Accuracy: 0.5185185185185185\n",
      "MCC = 0.26754502228372407\n",
      "AUC = {0: 0.5676691729323309, 1: 0.7676470588235296, 2: 0.5435897435897435}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "SVM_y_predicted_20 = SVMc(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "SVM_y_predicted_40 = SVMc(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df80d3c",
   "metadata": {},
   "source": [
    "### Random Forest classifier  for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef7c64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFc(X_train,X_test,y_train,y_test):\n",
    "    model = RandomForestClassifier().fit(X_train,y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    sRFC_y_predicted = model.predict_proba(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    \n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    y_predicted = label_binarize(preds, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"AUC =\",roc_auc)\n",
    "    \n",
    "    return sRFC_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a09f5463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.44      0.38         9\n",
      "           1       0.58      0.70      0.64        10\n",
      "           2       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.48        27\n",
      "   macro avg       0.53      0.46      0.46        27\n",
      "weighted avg       0.52      0.48      0.47        27\n",
      "\n",
      "Accuracy: 0.48148148148148145\n",
      "MCC = 0.21650635094610965\n",
      "AUC = {0: 0.5, 1: 0.7029411764705882, 2: 0.5986842105263158}\n",
      "Using 40% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14208\\3052431571.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14208\\3052431571.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.21      0.22        19\n",
      "           1       0.42      0.65      0.51        20\n",
      "           2       0.60      0.20      0.30        15\n",
      "\n",
      "    accuracy                           0.37        54\n",
      "   macro avg       0.41      0.35      0.34        54\n",
      "weighted avg       0.40      0.37      0.35        54\n",
      "\n",
      "Accuracy: 0.37037037037037035\n",
      "MCC = 0.024424013458612084\n",
      "AUC = {0: 0.4052631578947368, 1: 0.5602941176470588, 2: 0.5743589743589743}\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "RFc_y_predicted_20 = RFc(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "RFc_y_predicted420 = RFc(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40b2a8",
   "metadata": {},
   "source": [
    "### Logistic Regression for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b88a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train,X_test,y_train,y_test):\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs').fit(X_train,y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    sLR_y_predicted = model.predict_proba(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    \n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    y_predicted = label_binarize(preds, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"AUC =\",roc_auc)\n",
    "    \n",
    "    return sLR_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c49ed00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.50         9\n",
      "           1       0.69      0.90      0.78        10\n",
      "           2       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.66      0.66      0.65        27\n",
      "weighted avg       0.66      0.67      0.65        27\n",
      "\n",
      "Accuracy: 0.6666666666666666\n",
      "MCC = 0.5011926315100854\n",
      "AUC = {0: 0.6388888888888888, 1: 0.8323529411764704, 2: 0.7598684210526316}\n",
      "Using 40% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50        19\n",
      "           1       0.63      0.85      0.72        20\n",
      "           2       0.50      0.33      0.40        15\n",
      "\n",
      "    accuracy                           0.57        54\n",
      "   macro avg       0.55      0.55      0.54        54\n",
      "weighted avg       0.56      0.57      0.55        54\n",
      "\n",
      "Accuracy: 0.5740740740740741\n",
      "MCC = 0.35483623400235725\n",
      "AUC = {0: 0.6225563909774436, 1: 0.7779411764705882, 2: 0.6025641025641025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "LR_y_predicted_20 = LR(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "LR_y_predicted_40 = LR(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4956197",
   "metadata": {},
   "source": [
    "## Features Selection techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d95a1d",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE) -> backward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc872ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_xgb(X_train, y_train,X_test,learning_rate, n_estimators, max_depth,min_child_weight, gamma, subsample, colsample_bytree, simple):\n",
    "    min_features_to_select = 1\n",
    "    \n",
    "    #run RFE on current train subset\n",
    "    if simple:\n",
    "        clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False)\n",
    "    else:\n",
    "        clf = xgb.XGBClassifier(learning_rate = learning_rate, n_estimators = int(n_estimators), max_depth = int(max_depth), \n",
    "                                min_child_weight = min_child_weight, gamma = gamma, subsample = subsample, \n",
    "                                colsample_bytree = colsample_bytree, seed = 24,eval_metric='mlogloss',use_label_encoder =False)\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train)\n",
    "    \n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train.shape[1])\n",
    "    \n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67631c6e",
   "metadata": {},
   "source": [
    "### Test on XGB classifier using RFE selected features for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c5e9b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 71 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.56      0.50         9\n",
      "           1       0.50      0.40      0.44        10\n",
      "           2       0.38      0.38      0.38         8\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.44      0.44      0.44        27\n",
      "weighted avg       0.45      0.44      0.44        27\n",
      "\n",
      "Accuracy: 0.4444444444444444\n",
      "MCC = 0.1680512392345396\n",
      "AUC = {0: 0.6111111111111112, 1: 0.5823529411764705, 2: 0.555921052631579}\n"
     ]
    }
   ],
   "source": [
    "#test rfe then simple XGB classifier\n",
    "newX_train,newX_test = rfe_xgb(X_train_20, y_train_20,X_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "RFE_XGB_y_predicted_20 = XGB_class(newX_train,newX_test,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20974eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 110 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.37      0.37        19\n",
      "           1       0.41      0.55      0.47        20\n",
      "           2       0.50      0.27      0.35        15\n",
      "\n",
      "    accuracy                           0.41        54\n",
      "   macro avg       0.43      0.40      0.39        54\n",
      "weighted avg       0.42      0.41      0.40        54\n",
      "\n",
      "Accuracy: 0.4074074074074074\n",
      "MCC = 0.09055967695009846\n",
      "AUC = {0: 0.512781954887218, 1: 0.5397058823529413, 2: 0.582051282051282}\n"
     ]
    }
   ],
   "source": [
    "#test rfe then simple XGB classifier\n",
    "newX_train,newX_test = rfe_xgb(X_train_40, y_train_40,X_test_40,0,0,0,0,0,0,0,simple=True)\n",
    "RFE_XGB_y_predicted_40 = XGB_class(newX_train,newX_test,y_train_40,y_test_40,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19de70",
   "metadata": {},
   "source": [
    "### Test on SVM classifier using RFE selected features for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323f2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_SVM(X_train, y_train,X_test):\n",
    "    min_features_to_select = 1\n",
    "\n",
    "    #run RFE on current train subset\n",
    "    clf = SVC(kernel='linear',probability=True) \n",
    "\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train.shape[1])\n",
    "\n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bc49fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 56 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.33      0.35         9\n",
      "           1       0.75      0.90      0.82        10\n",
      "           2       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.57      0.58      0.57        27\n",
      "weighted avg       0.57      0.59      0.58        27\n",
      "\n",
      "Accuracy: 0.5925925925925926\n",
      "MCC = 0.3849675674847534\n",
      "AUC = {0: 0.5277777777777778, 1: 0.8617647058823529, 2: 0.6710526315789473}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#test rfe then SVM classifier\n",
    "newX_train,newX_test = rfe_SVM(X_train_20, y_train_20,X_test_20)\n",
    "RFE_SVM_y_predicted_20 = SVMc(newX_train,newX_test,y_train_20,y_test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43e31359",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 68 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.37      0.36        19\n",
      "           1       0.64      0.70      0.67        20\n",
      "           2       0.25      0.20      0.22        15\n",
      "\n",
      "    accuracy                           0.44        54\n",
      "   macro avg       0.41      0.42      0.42        54\n",
      "weighted avg       0.43      0.44      0.43        54\n",
      "\n",
      "Accuracy: 0.4444444444444444\n",
      "MCC = 0.15506438519186494\n",
      "AUC = {0: 0.49849624060150377, 1: 0.7323529411764705, 2: 0.48461538461538456}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#test rfe then SVM classifier\n",
    "newX_train,newX_test = rfe_SVM(X_train_40, y_train_40,X_test_40)\n",
    "RFE_SVM_y_predicted_40 = SVMc(newX_train,newX_test,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de2fe2a",
   "metadata": {},
   "source": [
    "### Test on RF classifier using RFE selected features for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "245831a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_RFc(X_train, y_train,X_test):\n",
    "    min_features_to_select = 1\n",
    "\n",
    "    #run RFE on current train subset\n",
    "    clf = RandomForestClassifier().fit(X_train,y_train)\n",
    "\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train.shape[1])\n",
    "\n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed2bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_20772\\999033815.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 77 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.33      0.30         9\n",
      "           1       0.58      0.70      0.64        10\n",
      "           2       0.50      0.25      0.33         8\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.45      0.43      0.42        27\n",
      "weighted avg       0.46      0.44      0.43        27\n",
      "\n",
      "Accuracy: 0.4444444444444444\n",
      "MCC = 0.1567693552822363\n",
      "AUC = {0: 0.4444444444444444, 1: 0.7029411764705882, 2: 0.5723684210526316}\n",
      "40 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_20772\\999033815.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 320 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.32      0.33        19\n",
      "           1       0.43      0.65      0.52        20\n",
      "           2       0.57      0.27      0.36        15\n",
      "\n",
      "    accuracy                           0.43        54\n",
      "   macro avg       0.45      0.41      0.41        54\n",
      "weighted avg       0.44      0.43      0.41        54\n",
      "\n",
      "Accuracy: 0.42592592592592593\n",
      "MCC = 0.11891568463930174\n",
      "AUC = {0: 0.5007518796992482, 1: 0.575, 2: 0.5948717948717949}\n"
     ]
    }
   ],
   "source": [
    "print(\"20 %\")\n",
    "newX_train,newX_test = rfe_RFc(X_train_20, y_train_20,X_test_20)\n",
    "RFE_RFc_y_predicted_20 = RFc(newX_train,newX_test,y_train_20,y_test_20)\n",
    "print(\"40 %\")\n",
    "newX_train,newX_test = rfe_RFc(X_train_40, y_train_40,X_test_40)\n",
    "RFE_RFc_y_predicted_40 = RFc(newX_train,newX_test,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31190b83",
   "metadata": {},
   "source": [
    "### Test on LR classifier using RFE selected features for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70b7bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_RFc(X_train, y_train,X_test):\n",
    "    min_features_to_select = 1\n",
    "\n",
    "    #run RFE on current train subset\n",
    "    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs').fit(X_train,y_train)\n",
    "\n",
    "\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train.shape[1])\n",
    "\n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9559c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 %\n",
      "We kept 56 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.33      0.35         9\n",
      "           1       0.75      0.90      0.82        10\n",
      "           2       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.57      0.58      0.57        27\n",
      "weighted avg       0.57      0.59      0.58        27\n",
      "\n",
      "Accuracy: 0.5925925925925926\n",
      "MCC = 0.3849675674847534\n",
      "AUC = {0: 0.5277777777777778, 1: 0.8617647058823529, 2: 0.6710526315789473}\n",
      "40 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 68 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.37      0.36        19\n",
      "           1       0.64      0.70      0.67        20\n",
      "           2       0.25      0.20      0.22        15\n",
      "\n",
      "    accuracy                           0.44        54\n",
      "   macro avg       0.41      0.42      0.42        54\n",
      "weighted avg       0.43      0.44      0.43        54\n",
      "\n",
      "Accuracy: 0.4444444444444444\n",
      "MCC = 0.15506438519186494\n",
      "AUC = {0: 0.49849624060150377, 1: 0.7323529411764705, 2: 0.48461538461538456}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"20 %\")\n",
    "newX_train,newX_test = rfe_SVM(X_train_20, y_train_20,X_test_20)\n",
    "RFE_LR_y_predicted_20 = SVMc(newX_train,newX_test,y_train_20,y_test_20)\n",
    "print(\"40 %\")\n",
    "newX_train,newX_test = rfe_SVM(X_train_40, y_train_40,X_test_40)\n",
    "RFE_LR_y_predicted_40 = SVMc(newX_train,newX_test,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f8f54",
   "metadata": {},
   "source": [
    "### Plot AUC-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4444b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_row(y_test,y_predicted,title):\n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    labels=['slow','rapid','stable']\n",
    "    colors = cycle(['blue', 'red', 'green'])\n",
    "    for i, color in zip(range(3), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(labels[i], roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124c27d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = 'ROC curve of each class of LR'\n",
    "single_row(y_test_20,LR_y_predicted_20,title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c794a8",
   "metadata": {},
   "source": [
    "### FORWARD ORDER using forward feature selection (Greedy Feature Selection Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9e9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_select(X_train, y_train):\n",
    "    \n",
    "    acc_imp = 0  \n",
    "    last_best_acc=1000\n",
    "    features_selected=[]\n",
    "    best_features = []\n",
    "    no_imp_counter=0\n",
    "    \n",
    "    while no_imp_counter<20:\n",
    "        accuracies = []\n",
    "        for i in range(len(X_train)):   \n",
    "            curr_X_train = X_train.iloc[:,i]\n",
    "            for j in range(len(features_selected)):\n",
    "                curr_X_train = pd.concat([curr_X_train, features_selected[j]],axis=1)\n",
    "            fs_X_train, fs_X_test, fs_y_train, fs_y_test = train_test_split(curr_X_train, y_train, test_size = 0.80, random_state = 97,stratify=y_train)\n",
    "\n",
    "            clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False,objective='multi:softproba')\n",
    "            clf.fit(fs_X_train, fs_y_train)\n",
    "            y_predicted = clf.predict_proba(fs_X_test)\n",
    "            accuracies.append(log_loss(fs_y_test, y_predicted))\n",
    "        \n",
    "        best_feature_idx=np.argmin(accuracies) \n",
    "        print('new best feature added =',X_train.iloc[:,best_feature_idx].name)\n",
    "        features_selected.append(X_train.iloc[:,best_feature_idx])\n",
    "        X_train.drop(X_train.columns[best_feature_idx],axis=1,inplace=True)\n",
    "        \n",
    "        curr_acc=accuracies[best_feature_idx]\n",
    "        print('new log loss =',curr_acc)\n",
    "        if curr_acc<last_best_acc:\n",
    "            acc_imp = last_best_acc-curr_acc\n",
    "            last_best_acc = curr_acc\n",
    "            best_features=features_selected.copy()\n",
    "            no_imp_counter=0\n",
    "            print('improvement of',acc_imp,'\\n')\n",
    "        else:\n",
    "            no_imp_counter+=1\n",
    "            print('no improvement for',no_imp_counter,'times \\n')\n",
    "\n",
    "    \n",
    "    print('-> last best log loss on training set =',last_best_acc)\n",
    "    \n",
    "    best_features_names = []\n",
    "    for i in best_features:\n",
    "        best_features_names.append(i.name)\n",
    "\n",
    "    return best_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c510970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Forward feature selection:\n",
      "new best feature added = CATD.YSQAVPAVTEGPIPEVLK\n",
      "new log loss = 1.342066453534296\n",
      "improvement of 998.6579335464658 \n",
      "\n",
      "new best feature added = CNTN2.IIVQAQPEWLK\n",
      "new log loss = 1.2342850686232933\n",
      "improvement of 0.10778138491100275 \n",
      "\n",
      "new best feature added = CFAB.YGLVTYATYPK\n",
      "new log loss = 1.1350263081191259\n",
      "improvement of 0.09925876050416749 \n",
      "\n",
      "new best feature added = CNDP1.ALEQDLPVNIK\n",
      "new log loss = 1.0735944995078548\n",
      "improvement of 0.061431808611271066 \n",
      "\n",
      "new best feature added = CMGA.SGELEQEEER\n",
      "new log loss = 1.0482630591368538\n",
      "improvement of 0.02533144037100099 \n",
      "\n",
      "new best feature added = AATC.LALGDDSPALK\n",
      "new log loss = 1.0662149140803978\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = CH3L1.VTIDSSYDIAK\n",
      "new log loss = 1.0158008875689288\n",
      "improvement of 0.03246217156792497 \n",
      "\n",
      "new best feature added = CMGA.SGEATDGARPQALPEPMQESK\n",
      "new log loss = 1.0111668634003605\n",
      "improvement of 0.004634024168568285 \n",
      "\n",
      "new best feature added = CO4A.VTASDPLDTLGSEGALSPGGVASLLR\n",
      "new log loss = 1.014022954450599\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = CFAB.VSEADSSNADWVTK\n",
      "new log loss = 0.9913987107146746\n",
      "improvement of 0.01976815268568599 \n",
      "\n",
      "new best feature added = CFAB.DAQYAPGYDK\n",
      "new log loss = 0.9787879970738258\n",
      "improvement of 0.012610713640848759 \n",
      "\n",
      "new best feature added = CO2.HAIILLTDGK\n",
      "new log loss = 0.9930693525606873\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = CATD.VSTLPAITLK\n",
      "new log loss = 0.9820691237932649\n",
      "no improvement for 2 times \n",
      "\n",
      "new best feature added = CO5.DINYVNPVIK\n",
      "new log loss = 1.0036783114760772\n",
      "no improvement for 3 times \n",
      "\n",
      "new best feature added = AMBP.ETLLQDFR\n",
      "new log loss = 1.012656609945256\n",
      "no improvement for 4 times \n",
      "\n",
      "new best feature added = APOB.SVSLPSLDPASAK\n",
      "new log loss = 0.9962998845068545\n",
      "no improvement for 5 times \n",
      "\n",
      "new best feature added = CD59.AGLQVYNK\n",
      "new log loss = 0.9912922556629811\n",
      "no improvement for 6 times \n",
      "\n",
      "new best feature added = AATC.IVASTLSNPELFEEWTGNVK\n",
      "new log loss = 0.9932466835939678\n",
      "no improvement for 7 times \n",
      "\n",
      "new best feature added = CO4A.GSFEFPVGDAVSK\n",
      "new log loss = 0.9836730389245625\n",
      "no improvement for 8 times \n",
      "\n",
      "new best feature added = CMGA.YPGPQAEGDSEGLSQGLVDR\n",
      "new log loss = 1.0167873970436296\n",
      "no improvement for 9 times \n",
      "\n",
      "new best feature added = CADM3.GNPVPQQYLWEK\n",
      "new log loss = 1.0184149311148916\n",
      "no improvement for 10 times \n",
      "\n",
      "new best feature added = CO6.SEYGAALAWEK\n",
      "new log loss = 1.0036472055161823\n",
      "no improvement for 11 times \n",
      "\n",
      "new best feature added = CAD13.YEVSSPYFK\n",
      "new log loss = 1.0154753968376538\n",
      "no improvement for 12 times \n",
      "\n",
      "new best feature added = CNTN2.VIASNILGTGEPSGPSSK\n",
      "new log loss = 0.9982230997719299\n",
      "no improvement for 13 times \n",
      "\n",
      "new best feature added = B2MG.VEHSDLSFSK\n",
      "new log loss = 0.9941388224733287\n",
      "no improvement for 14 times \n",
      "\n",
      "new best feature added = CAD13.DIQGSLQDIFK\n",
      "new log loss = 1.0045938950845565\n",
      "no improvement for 15 times \n",
      "\n",
      "new best feature added = CLUS.IDSLLENDR\n",
      "new log loss = 0.9766185366730581\n",
      "improvement of 0.0021694604007677087 \n",
      "\n",
      "new best feature added = CD14.FPAIQNLALR\n",
      "new log loss = 1.0244229573799275\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = APOE.CLAVYQAGAR\n",
      "new log loss = 1.029477184788249\n",
      "no improvement for 2 times \n",
      "\n",
      "new best feature added = CD14.SWLAELQQWLKPGLK\n",
      "new log loss = 1.0305372315576706\n",
      "no improvement for 3 times \n",
      "\n",
      "new best feature added = CO8B.SDLEVAHYK\n",
      "new log loss = 1.0443529602268646\n",
      "no improvement for 4 times \n",
      "\n",
      "new best feature added = CD14.AFPALTSLDLSDNPGLGER\n",
      "new log loss = 1.0527193605385978\n",
      "no improvement for 5 times \n",
      "\n",
      "new best feature added = A1BG.SGLSTGWTQLSK\n",
      "new log loss = 1.053289447365136\n",
      "no improvement for 6 times \n",
      "\n",
      "new best feature added = DAG1.GVHYISVSATR\n",
      "new log loss = 1.0402249163766017\n",
      "no improvement for 7 times \n",
      "\n",
      "new best feature added = CO5.VFQFLEK\n",
      "new log loss = 1.0465102954500023\n",
      "no improvement for 8 times \n",
      "\n",
      "new best feature added = AMBP.AFIQLWAFDAVK\n",
      "new log loss = 1.048944956012841\n",
      "no improvement for 9 times \n",
      "\n",
      "new best feature added = CSTN3.ATGEGLIR\n",
      "new log loss = 1.0554350892874016\n",
      "no improvement for 10 times \n",
      "\n",
      "new best feature added = FAM3C.SALDTAAR\n",
      "new log loss = 1.0824642881922337\n",
      "no improvement for 11 times \n",
      "\n",
      "new best feature added = CO4A.VLSLAQEQVGGSPEK\n",
      "new log loss = 1.0607389829967213\n",
      "no improvement for 12 times \n",
      "\n",
      "new best feature added = CAD13.INENTGSVSVTR\n",
      "new log loss = 1.0522974694426033\n",
      "no improvement for 13 times \n",
      "\n",
      "new best feature added = C1QB.VPGLYYFTYHASSR\n",
      "new log loss = 1.0359965460053806\n",
      "no improvement for 14 times \n",
      "\n",
      "new best feature added = CNTN1.DGEYVVEVR\n",
      "new log loss = 1.0543331777912446\n",
      "no improvement for 15 times \n",
      "\n",
      "new best feature added = CCKN.AHLGALLAR\n",
      "new log loss = 1.051758779020145\n",
      "no improvement for 16 times \n",
      "\n",
      "new best feature added = BASP1.ETPAATEAPSSTPK\n",
      "new log loss = 1.037838944672853\n",
      "no improvement for 17 times \n",
      "\n",
      "new best feature added = AACT.EIGELYLPK\n",
      "new log loss = 1.0317960150282959\n",
      "no improvement for 18 times \n",
      "\n",
      "new best feature added = FAM3C.SPFEQHIK\n",
      "new log loss = 1.0479722903377708\n",
      "no improvement for 19 times \n",
      "\n",
      "new best feature added = FBLN3.IPSNPSHR\n",
      "new log loss = 1.054341822348792\n",
      "no improvement for 20 times \n",
      "\n",
      "-> last best log loss on training set = 0.9766185366730581\n",
      "We kept 27 features out of the 320\n",
      "2) XGB with forward feature selection\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.62      0.80      0.70        10\n",
      "           2       0.60      0.38      0.46         8\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.59      0.58      0.57        27\n",
      "weighted avg       0.59      0.59      0.58        27\n",
      "\n",
      "Accuracy: 0.5925925925925926\n",
      "MCC = 0.38612504117259866\n",
      "AUC = {0: 0.6666666666666667, 1: 0.7529411764705882, 2: 0.6348684210526316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14208\\48801181.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  newX_test = X_test_20[(newX_train.columns) & (X_test_20.columns)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8981927 , 0.04257743, 0.0592299 ],\n",
       "       [0.04032784, 0.93813324, 0.02153898],\n",
       "       [0.11148787, 0.10848126, 0.78003085],\n",
       "       [0.38181877, 0.18956146, 0.4286198 ],\n",
       "       [0.00566998, 0.98815453, 0.00617543],\n",
       "       [0.7493525 , 0.07113768, 0.17950982],\n",
       "       [0.0809505 , 0.8244039 , 0.09464566],\n",
       "       [0.8819124 , 0.03138743, 0.08670016],\n",
       "       [0.7628539 , 0.23414762, 0.00299845],\n",
       "       [0.10695112, 0.12006779, 0.7729811 ],\n",
       "       [0.9911646 , 0.00618158, 0.00265379],\n",
       "       [0.1028212 , 0.8620408 , 0.03513798],\n",
       "       [0.26013115, 0.62074155, 0.11912728],\n",
       "       [0.8553514 , 0.08178139, 0.06286719],\n",
       "       [0.10611061, 0.509487  , 0.3844024 ],\n",
       "       [0.282826  , 0.582155  , 0.13501902],\n",
       "       [0.1457948 , 0.23695537, 0.61724985],\n",
       "       [0.00796282, 0.7832039 , 0.20883326],\n",
       "       [0.41502237, 0.22214872, 0.36282888],\n",
       "       [0.08900953, 0.22671291, 0.6842776 ],\n",
       "       [0.03038352, 0.9486815 , 0.02093503],\n",
       "       [0.63474953, 0.15976182, 0.20548865],\n",
       "       [0.05578231, 0.70485073, 0.23936696],\n",
       "       [0.17702115, 0.53823245, 0.28474644],\n",
       "       [0.13951387, 0.8526822 , 0.00780398],\n",
       "       [0.85925   , 0.00278754, 0.13796248],\n",
       "       [0.06899229, 0.82841057, 0.10259714]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test tuning XGB hyperparameters with selected features from forward selection\n",
    "print('1) Forward feature selection:')\n",
    "fs_best_features = forward_select(X_train_20.copy(), y_train_20)\n",
    "newX_train = X_train_20.loc[:,fs_best_features]\n",
    "newX_test = X_test_20[(newX_train.columns) & (X_test_20.columns)]\n",
    "print('We kept',newX_train.shape[1],'features out of the',X_train_20.shape[1])\n",
    "print('2) XGB with forward feature selection')\n",
    "XGB_class(newX_train,newX_test,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f179df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Forward feature selection:\n",
      "new best feature added = APLP2.HYQHVLAVDPEK\n",
      "new log loss = 1.359009668460259\n",
      "improvement of 998.6409903315398 \n",
      "\n",
      "new best feature added = CFAB.DAQYAPGYDK\n",
      "new log loss = 1.3320168717549397\n",
      "improvement of 0.0269927967053194 \n",
      "\n",
      "new best feature added = APOE.LAVYQAGAR\n",
      "new log loss = 1.2031554226691907\n",
      "improvement of 0.12886144908574892 \n",
      "\n",
      "new best feature added = A1BG.SGLSTGWTQLSK\n",
      "new log loss = 1.152985826593179\n",
      "improvement of 0.05016959607601179 \n",
      "\n",
      "new best feature added = A1BG.NGVAQEPVHLDSPAIK\n",
      "new log loss = 1.1275840367835301\n",
      "improvement of 0.0254017898096488 \n",
      "\n",
      "new best feature added = BASP1.ETPAATEAPSSTPK\n",
      "new log loss = 1.1503074237360404\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = B3GN1.TALASGGVLDASGDYR\n",
      "new log loss = 1.1600045345150507\n",
      "no improvement for 2 times \n",
      "\n",
      "new best feature added = ALDOA.ALQASALK\n",
      "new log loss = 1.1316222896656165\n",
      "no improvement for 3 times \n",
      "\n",
      "new best feature added = A1AT.AVLTIDEK\n",
      "new log loss = 1.0452849538280413\n",
      "improvement of 0.08229908295548882 \n",
      "\n",
      "new best feature added = A4.THPHFVIPYR\n",
      "new log loss = 1.011922468818151\n",
      "improvement of 0.033362485009890364 \n",
      "\n",
      "new best feature added = AATC.IVASTLSNPELFEEWTGNVK\n",
      "new log loss = 0.9646958218171047\n",
      "improvement of 0.047226647001046285 \n",
      "\n",
      "new best feature added = CLUS.VTTVASHTSDSDVPSGVTEVVVK\n",
      "new log loss = 0.959293005328912\n",
      "improvement of 0.00540281648819263 \n",
      "\n",
      "new best feature added = CNTN1.DGEYVVEVR\n",
      "new log loss = 0.9634727950852651\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = CNTN2.IIVQAQPEWLK\n",
      "new log loss = 0.9488114021145381\n",
      "improvement of 0.010481603214373969 \n",
      "\n",
      "new best feature added = A4.LVFFAEDVGSNK\n",
      "new log loss = 0.9654675589731107\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = CH3L1.ILGQQVPYATK\n",
      "new log loss = 0.9453856924978586\n",
      "improvement of 0.0034257096166794287 \n",
      "\n",
      "new best feature added = B2MG.VNHVTLSQPK\n",
      "new log loss = 0.9459630398796155\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = AFAM.DADPDTFFAK\n",
      "new log loss = 0.9504552481266169\n",
      "no improvement for 2 times \n",
      "\n",
      "new best feature added = CERU.NNEGTYYSPNYNPQSR\n",
      "new log loss = 0.9614372342824936\n",
      "no improvement for 3 times \n",
      "\n",
      "new best feature added = APOB.TGISPLALIK\n",
      "new log loss = 0.9628109382895323\n",
      "no improvement for 4 times \n",
      "\n",
      "new best feature added = AATC.NLDYVATSIHEAVTK\n",
      "new log loss = 0.9829430137689297\n",
      "no improvement for 5 times \n",
      "\n",
      "new best feature added = CNTN2.VIASNILGTGEPSGPSSK\n",
      "new log loss = 0.9485765910492494\n",
      "no improvement for 6 times \n",
      "\n",
      "new best feature added = AATM.FVTVQTISGTGALR\n",
      "new log loss = 0.9634261966897891\n",
      "no improvement for 7 times \n",
      "\n",
      "new best feature added = CO2.SSGQWQTPGATR\n",
      "new log loss = 0.9671429644983548\n",
      "no improvement for 8 times \n",
      "\n",
      "new best feature added = CERU.IYHSHIDAPK\n",
      "new log loss = 0.9658780372486665\n",
      "no improvement for 9 times \n",
      "\n",
      "new best feature added = CO2.DFHINLFR\n",
      "new log loss = 0.9713938537125404\n",
      "no improvement for 10 times \n",
      "\n",
      "new best feature added = CO3.VPVAVQGEDTVQSLTQGDGVAK\n",
      "new log loss = 0.9279369369149209\n",
      "improvement of 0.01744875558293779 \n",
      "\n",
      "new best feature added = CNDP1.WNYIEGTK\n",
      "new log loss = 0.9215638724084084\n",
      "improvement of 0.006373064506512427 \n",
      "\n",
      "new best feature added = CH3L1.VTIDSSYDIAK\n",
      "new log loss = 0.9102990603217712\n",
      "improvement of 0.01126481208663721 \n",
      "\n",
      "new best feature added = CFAB.YGLVTYATYPK\n",
      "new log loss = 0.8984893010785946\n",
      "improvement of 0.01180975924317662 \n",
      "\n",
      "new best feature added = AFAM.LPNNVLQEK\n",
      "new log loss = 0.900061117284573\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = C1QB.LEQGENVFLQATDK\n",
      "new log loss = 0.9272277113336783\n",
      "no improvement for 2 times \n",
      "\n",
      "new best feature added = CO3.TELRPGETLNVNFLLR\n",
      "new log loss = 0.9355720951006963\n",
      "no improvement for 3 times \n",
      "\n",
      "new best feature added = AACT.EIGELYLPK\n",
      "new log loss = 0.9116023573164757\n",
      "no improvement for 4 times \n",
      "\n",
      "new best feature added = CO5.DINYVNPVIK\n",
      "new log loss = 0.9303471190425066\n",
      "no improvement for 5 times \n",
      "\n",
      "new best feature added = CO5.VFQFLEK\n",
      "new log loss = 0.9308576000424532\n",
      "no improvement for 6 times \n",
      "\n",
      "new best feature added = APOE.LGPLVEQGR\n",
      "new log loss = 0.9153324202276193\n",
      "no improvement for 7 times \n",
      "\n",
      "new best feature added = CO6.ALNHLPLEYNSALYSR\n",
      "new log loss = 0.9107789306686475\n",
      "no improvement for 8 times \n",
      "\n",
      "new best feature added = AMD.NGQWTLIGR\n",
      "new log loss = 0.9181796239545712\n",
      "no improvement for 9 times \n",
      "\n",
      "new best feature added = AFAM.FLVNLVK\n",
      "new log loss = 0.9325410952934852\n",
      "no improvement for 10 times \n",
      "\n",
      "new best feature added = CMGA.SEALAVDGAGKPGAEEAQDPEGK\n",
      "new log loss = 0.9499145951408606\n",
      "no improvement for 11 times \n",
      "\n",
      "new best feature added = CO4A.NVNFQK\n",
      "new log loss = 0.9678770869970321\n",
      "no improvement for 12 times \n",
      "\n",
      "new best feature added = CNTP2.YSSSDWVTQYR\n",
      "new log loss = 0.9621806718122501\n",
      "no improvement for 13 times \n",
      "\n",
      "new best feature added = CRP.ESDTSYVSLK\n",
      "new log loss = 1.0025979953316542\n",
      "no improvement for 14 times \n",
      "\n",
      "new best feature added = APOE.CLAVYQAGAR\n",
      "new log loss = 0.9860891173092219\n",
      "no improvement for 15 times \n",
      "\n",
      "new best feature added = CO2.HAIILLTDGK\n",
      "new log loss = 1.0115833866195036\n",
      "no improvement for 16 times \n",
      "\n",
      "new best feature added = CSTN3.ATGEGLIR\n",
      "new log loss = 1.0050134317233013\n",
      "no improvement for 17 times \n",
      "\n",
      "new best feature added = CO3.IHWESASLLR\n",
      "new log loss = 0.9590270715264174\n",
      "no improvement for 18 times \n",
      "\n",
      "new best feature added = B3GN1.YEAAVPDPR\n",
      "new log loss = 0.987637186394288\n",
      "no improvement for 19 times \n",
      "\n",
      "new best feature added = CNTN2.TTGPGGDGIPAEVHIVR\n",
      "new log loss = 0.9917940497398376\n",
      "no improvement for 20 times \n",
      "\n",
      "-> last best log loss on training set = 0.8984893010785946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_20772\\1462326117.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  newX_test = X_test_40[(newX_train.columns) & (X_test_40.columns)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 30 features out of the 320\n",
      "2) XGB with forward feature selection\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.32      0.28        19\n",
      "           1       0.41      0.45      0.43        20\n",
      "           2       0.25      0.13      0.17        15\n",
      "\n",
      "    accuracy                           0.31        54\n",
      "   macro avg       0.30      0.30      0.29        54\n",
      "weighted avg       0.31      0.31      0.31        54\n",
      "\n",
      "Accuracy: 0.3148148148148148\n",
      "MCC = -0.05269609319809172\n",
      "AUC = {0: 0.4007518796992482, 1: 0.5338235294117647, 2: 0.4897435897435897}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01335126, 0.9810296 , 0.00561906],\n",
       "       [0.5538356 , 0.38455567, 0.0616088 ],\n",
       "       [0.16249552, 0.7936623 , 0.04384219],\n",
       "       [0.9016113 , 0.05470495, 0.04368374],\n",
       "       [0.08770977, 0.37356755, 0.5387227 ],\n",
       "       [0.0092732 , 0.9253433 , 0.06538352],\n",
       "       [0.3786369 , 0.32308802, 0.29827505],\n",
       "       [0.6426644 , 0.31161636, 0.0457193 ],\n",
       "       [0.46612796, 0.5099951 , 0.02387691],\n",
       "       [0.23158817, 0.0589674 , 0.7094444 ],\n",
       "       [0.17444102, 0.08912026, 0.73643875],\n",
       "       [0.02410617, 0.8836313 , 0.09226248],\n",
       "       [0.03741487, 0.9542726 , 0.00831245],\n",
       "       [0.7316105 , 0.06293666, 0.20545286],\n",
       "       [0.17430286, 0.74760723, 0.0780899 ],\n",
       "       [0.0938181 , 0.7880533 , 0.11812865],\n",
       "       [0.8574136 , 0.10630322, 0.03628322],\n",
       "       [0.06523383, 0.05804871, 0.87671745],\n",
       "       [0.7880333 , 0.20536782, 0.00659895],\n",
       "       [0.35484812, 0.45660925, 0.1885427 ],\n",
       "       [0.6730663 , 0.26792717, 0.05900649],\n",
       "       [0.03191578, 0.9124872 , 0.05559703],\n",
       "       [0.05766886, 0.722089  , 0.22024216],\n",
       "       [0.7519059 , 0.04064986, 0.20744428],\n",
       "       [0.9616461 , 0.02615747, 0.0121964 ],\n",
       "       [0.8287372 , 0.04315865, 0.12810412],\n",
       "       [0.41956913, 0.05990805, 0.52052283],\n",
       "       [0.8087319 , 0.1573262 , 0.03394192],\n",
       "       [0.10296628, 0.89465564, 0.0023781 ],\n",
       "       [0.04955707, 0.8840239 , 0.06641907],\n",
       "       [0.23449937, 0.5270892 , 0.2384115 ],\n",
       "       [0.8443595 , 0.04830882, 0.10733169],\n",
       "       [0.81500345, 0.17141116, 0.01358537],\n",
       "       [0.24958971, 0.64929277, 0.10111752],\n",
       "       [0.9940584 , 0.00379647, 0.0021452 ],\n",
       "       [0.6650509 , 0.31258467, 0.02236441],\n",
       "       [0.0068015 , 0.98735875, 0.0058397 ],\n",
       "       [0.14407115, 0.05184007, 0.8040888 ],\n",
       "       [0.49354032, 0.48933536, 0.01712434],\n",
       "       [0.764356  , 0.09868977, 0.13695417],\n",
       "       [0.29439542, 0.38803604, 0.31756857],\n",
       "       [0.00786466, 0.98761475, 0.00452062],\n",
       "       [0.3331109 , 0.07297863, 0.59391046],\n",
       "       [0.13934545, 0.69143826, 0.16921625],\n",
       "       [0.01246068, 0.21767864, 0.76986074],\n",
       "       [0.06773152, 0.89960694, 0.03266156],\n",
       "       [0.9022314 , 0.07993759, 0.01783103],\n",
       "       [0.7513197 , 0.24301282, 0.00566747],\n",
       "       [0.8997286 , 0.0484206 , 0.05185084],\n",
       "       [0.7913555 , 0.01105681, 0.19758767],\n",
       "       [0.10162214, 0.87392694, 0.02445087],\n",
       "       [0.7367224 , 0.00725853, 0.2560191 ],\n",
       "       [0.2129291 , 0.7356844 , 0.05138655],\n",
       "       [0.65848   , 0.2734116 , 0.06810838]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test tuning XGB hyperparameters with selected features from forward selection\n",
    "print('1) Forward feature selection:')\n",
    "fs_best_features = forward_select(X_train_40.copy(), y_train_40)\n",
    "newX_train = X_train_40.loc[:,fs_best_features]\n",
    "newX_test = X_test_40[(newX_train.columns) & (X_test_40.columns)]\n",
    "print('We kept',newX_train.shape[1],'features out of the',X_train_40.shape[1])\n",
    "print('2) XGB with forward feature selection')\n",
    "XGB_class(newX_train,newX_test,y_train_40,y_test_40,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017dfd00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
