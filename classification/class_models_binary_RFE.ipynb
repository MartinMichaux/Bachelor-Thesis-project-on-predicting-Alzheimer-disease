{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a83341",
   "metadata": {},
   "source": [
    "# Build binary classification models where some use RFE selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d435b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)\n",
    "from sklearn.feature_selection import RFECV\n",
    "import random\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a92679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first column of dataframe\n",
    "def drop_first_col(df):\n",
    "    return df.iloc[: , 1:]\n",
    "\n",
    "X_train_20 = pd.read_csv(\"dataset\\X_train_2_20.csv\")\n",
    "X_test_20 = pd.read_csv(\"dataset\\X_test_2_20.csv\")\n",
    "y_train_20 = pd.read_csv(\"dataset\\y_train_2_20.csv\")\n",
    "y_test_20 = pd.read_csv(\"dataset\\y_test_2_20.csv\")\n",
    "\n",
    "X_train_40 = pd.read_csv(\"dataset\\X_train_2_40.csv\")\n",
    "X_test_40 = pd.read_csv(\"dataset\\X_test_2_40.csv\")\n",
    "y_train_40 = pd.read_csv(\"dataset\\y_train_2_40.csv\")\n",
    "y_test_40 = pd.read_csv(\"dataset\\y_test_2_40.csv\")\n",
    "\n",
    "# X_train_20 = pd.read_csv(\"dataset\\otherD_X_train_2_20.csv\")\n",
    "# X_test_20 = pd.read_csv(\"dataset\\otherD_X_test_2_20.csv\")\n",
    "# y_train_20 = pd.read_csv(\"dataset\\otherD_y_train_2_20.csv\")\n",
    "# y_test_20 = pd.read_csv(\"dataset\\otherD_y_test_2_20.csv\")\n",
    "\n",
    "# X_train_40 = pd.read_csv(\"dataset\\otherD_X_train_2_40.csv\")\n",
    "# X_test_40 = pd.read_csv(\"dataset\\otherD_X_test_2_40.csv\")\n",
    "# y_train_40 = pd.read_csv(\"dataset\\otherD_y_train_2_40.csv\")\n",
    "# y_test_40 = pd.read_csv(\"dataset\\otherD_y_test_2_40.csv\")\n",
    "\n",
    "X_train_20 = drop_first_col(X_train_20)\n",
    "X_test_20 = drop_first_col(X_test_20)\n",
    "y_train_20 = drop_first_col(y_train_20)\n",
    "y_test_20 = drop_first_col(y_test_20)\n",
    "\n",
    "X_train_40 = drop_first_col(X_train_40)\n",
    "X_test_40 = drop_first_col(X_test_40)\n",
    "y_train_40 = drop_first_col(y_train_40)\n",
    "y_test_40 = drop_first_col(y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c6482",
   "metadata": {},
   "source": [
    "## Test on commonly used models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c80bba",
   "metadata": {},
   "source": [
    "### XGB Classifier for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc922337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_class(X_train, X_test, y_train, y_test,learning_rate, n_estimators, max_depth,min_child_weight, gamma, subsample, colsample_bytree, simple):\n",
    "    \n",
    "    if simple:\n",
    "        clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False)\n",
    "    else:\n",
    "        clf = xgb.XGBClassifier(learning_rate = learning_rate, n_estimators = int(n_estimators), max_depth = int(max_depth), \n",
    "                                min_child_weight = min_child_weight, gamma = gamma, subsample = subsample, \n",
    "                                colsample_bytree = colsample_bytree, seed = 24,eval_metric='mlogloss',use_label_encoder =False)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_predicted))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, y_predicted))\n",
    "    print(\"AUC =\",metrics.roc_auc_score(y_test, y_predicted))\n",
    "    \n",
    "    return clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c01f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         8\n",
      "           1       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.83      0.67      0.65        14\n",
      "weighted avg       0.81      0.71      0.67        14\n",
      "\n",
      "Accuracy: 0.7142857142857143\n",
      "MCC = 0.47140452079103173\n",
      "AUC = 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74        16\n",
      "           1       0.67      0.33      0.44        12\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.65      0.60      0.59        28\n",
      "weighted avg       0.65      0.64      0.61        28\n",
      "\n",
      "Accuracy: 0.6428571428571429\n",
      "MCC = 0.251259453814803\n",
      "AUC = 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "XGBc_y_predicted_20 = XGB_class(X_train_20,X_test_20,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "XGBc_y_predicted_40 = XGB_class(X_train_40,X_test_40,y_train_40,y_test_40,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8885d3",
   "metadata": {},
   "source": [
    "### SVM for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2de33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMc(X_train,X_test,y_train,y_test):\n",
    "    clf = SVC(kernel='linear',probability=True) \n",
    "    clf.fit(X_train, y_train) \n",
    "    preds = clf.predict(X_test)\n",
    "    sSVM_y_predicted = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    print(\"AUC =\",metrics.roc_auc_score(y_test, preds))\n",
    "    \n",
    "    return sSVM_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c7d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.48        10\n",
      "           1       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.57      0.57      0.57        27\n",
      "weighted avg       0.60      0.59      0.60        27\n",
      "\n",
      "Accuracy: 0.5925925925925926\n",
      "MCC = 0.1445304031446501\n",
      "AUC = 0.5735294117647058\n",
      "Using 40% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67        21\n",
      "           1       0.78      0.85      0.81        33\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.75      0.73      0.74        54\n",
      "weighted avg       0.76      0.76      0.76        54\n",
      "\n",
      "Accuracy: 0.7592592592592593\n",
      "MCC = 0.48349377841522817\n",
      "AUC = 0.7337662337662338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "SVM_y_predicted_20 = SVMc(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "SVM_y_predicted_40 = SVMc(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df80d3c",
   "metadata": {},
   "source": [
    "### Random Forest classifier for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7c64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFc(X_train,X_test,y_train,y_test):\n",
    "    model = RandomForestClassifier().fit(X_train,y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    sRFC_y_predicted = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    print(\"AUC =\",metrics.roc_auc_score(y_test, preds))\n",
    "    \n",
    "    return sRFC_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a09f5463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3304\\1229368516.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78         8\n",
      "           1       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.72      0.69      0.69        14\n",
      "weighted avg       0.72      0.71      0.70        14\n",
      "\n",
      "Accuracy: 0.7142857142857143\n",
      "MCC = 0.41079191812887456\n",
      "AUC = 0.6875\n",
      "Using 40% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3304\\1229368516.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        16\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.57        28\n",
      "   macro avg       0.29      0.50      0.36        28\n",
      "weighted avg       0.33      0.57      0.42        28\n",
      "\n",
      "Accuracy: 0.5714285714285714\n",
      "MCC = 0.0\n",
      "AUC = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "RFc_y_predicted_20 = RFc(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "RFc_y_predicted_40 = RFc(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40b2a8",
   "metadata": {},
   "source": [
    "### Logistic Regressor for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b88a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train,X_test,y_train,y_test):\n",
    "    model = LogisticRegression(random_state=0).fit(X_train,y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    sLR_y_predicted = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    print(\"AUC =\",metrics.roc_auc_score(y_test, preds))\n",
    "    \n",
    "    return sLR_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49ed00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         8\n",
      "           1       0.33      0.33      0.33         6\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.42      0.42      0.42        14\n",
      "weighted avg       0.43      0.43      0.43        14\n",
      "\n",
      "Accuracy: 0.42857142857142855\n",
      "MCC = -0.16666666666666666\n",
      "AUC = 0.41666666666666663\n",
      "Using 40% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.69      0.63        16\n",
      "           1       0.44      0.33      0.38        12\n",
      "\n",
      "    accuracy                           0.54        28\n",
      "   macro avg       0.51      0.51      0.50        28\n",
      "weighted avg       0.52      0.54      0.52        28\n",
      "\n",
      "Accuracy: 0.5357142857142857\n",
      "MCC = 0.022075539284417398\n",
      "AUC = 0.5104166666666666\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "LR_y_predicted_20 = LR(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "LR_y_predicted_40 = LR(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4956197",
   "metadata": {},
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d95a1d",
   "metadata": {},
   "source": [
    "### Backward: Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67631c6e",
   "metadata": {},
   "source": [
    "### Test on XGB classifier using RFE selected features for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc872ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_xgb(X_train, y_train,X_test,learning_rate, n_estimators, max_depth,min_child_weight, gamma, subsample, colsample_bytree, simple):\n",
    "    min_features_to_select = 1\n",
    "    \n",
    "    #run RFE on current train subset\n",
    "    if simple:\n",
    "        clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False)\n",
    "    else:\n",
    "        clf = xgb.XGBClassifier(learning_rate = learning_rate, n_estimators = int(n_estimators), max_depth = int(max_depth), \n",
    "                                min_child_weight = min_child_weight, gamma = gamma, subsample = subsample, \n",
    "                                colsample_bytree = colsample_bytree, seed = 24,eval_metric='mlogloss',use_label_encoder =False)\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train)\n",
    "    \n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train.shape[1])\n",
    "    \n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c5e9b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "We kept 8 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.30      0.37        10\n",
      "           1       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.58      0.56      0.56        27\n",
      "weighted avg       0.60      0.63      0.60        27\n",
      "\n",
      "Accuracy: 0.6296296296296297\n",
      "MCC = 0.14348601079588788\n",
      "AUC = 0.5617647058823529\n",
      "Using 40% as test subset:\n",
      "We kept 17 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.24      0.30        21\n",
      "           1       0.62      0.79      0.69        33\n",
      "\n",
      "    accuracy                           0.57        54\n",
      "   macro avg       0.52      0.51      0.50        54\n",
      "weighted avg       0.54      0.57      0.54        54\n",
      "\n",
      "Accuracy: 0.5740740740740741\n",
      "MCC = 0.030457245193658635\n",
      "AUC = 0.512987012987013\n"
     ]
    }
   ],
   "source": [
    "#test rfe then simple XGB classifier\n",
    "print('Using 20% as test subset:')\n",
    "newX_train,newX_test = rfe_xgb(X_train_20, y_train_20,X_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "RFE_XGB_y_predicted_20 = XGB_class(newX_train,newX_test,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "print('Using 40% as test subset:')\n",
    "newX_train,newX_test = rfe_xgb(X_train_40, y_train_40,X_test_40,0,0,0,0,0,0,0,simple=True)\n",
    "RFE_XGB_y_predicted_40 = XGB_class(newX_train,newX_test,y_train_40,y_test_40,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19de70",
   "metadata": {},
   "source": [
    "### Test on SVM classifier using RFE selected features for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43e31359",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rfe_SVM(X_train, y_train,X_test):\n",
    "    min_features_to_select = 1\n",
    "\n",
    "    #run RFE on current train subset\n",
    "    clf = SVC(kernel='linear',probability=True) \n",
    "\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train_40.shape[1])\n",
    "\n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f76afc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "We kept 20 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.60      0.57        10\n",
      "           1       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.65      0.65      0.65        27\n",
      "weighted avg       0.67      0.67      0.67        27\n",
      "\n",
      "Accuracy: 0.6666666666666666\n",
      "MCC = 0.3006232385408722\n",
      "AUC = 0.6529411764705884\n",
      "Using 40% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 200 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68        21\n",
      "           1       0.78      0.88      0.83        33\n",
      "\n",
      "    accuracy                           0.78        54\n",
      "   macro avg       0.77      0.75      0.76        54\n",
      "weighted avg       0.78      0.78      0.77        54\n",
      "\n",
      "Accuracy: 0.7777777777777778\n",
      "MCC = 0.5225491613224563\n",
      "AUC = 0.748917748917749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#test rfe then SVM classifier\n",
    "print('Using 20% as test subset:')\n",
    "newX_train,newX_test = rfe_SVM(X_train_20, y_train_20,X_test_20)\n",
    "RFE_SVM_y_predicted_20 = SVMc(newX_train,newX_test,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "newX_train,newX_test = rfe_SVM(X_train_40, y_train_40,X_test_40)\n",
    "RFE_SVM_y_predicted_40 = SVMc(newX_train,newX_test,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061300f",
   "metadata": {},
   "source": [
    "### Test on LR classifier using RFE selected features for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6761baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_LR(X_train, y_train,X_test):\n",
    "    min_features_to_select = 1\n",
    "\n",
    "    #run RFE on current train subset\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train_40.shape[1])\n",
    "\n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63898488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 98 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.40      0.42        10\n",
      "           1       0.67      0.71      0.69        17\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.56      0.55      0.55        27\n",
      "weighted avg       0.58      0.59      0.59        27\n",
      "\n",
      "Accuracy: 0.5925925925925926\n",
      "MCC = 0.1084652289093281\n",
      "AUC = 0.5529411764705883\n",
      "Using 40% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 269 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.48      0.56        21\n",
      "           1       0.72      0.85      0.78        33\n",
      "\n",
      "    accuracy                           0.70        54\n",
      "   macro avg       0.69      0.66      0.67        54\n",
      "weighted avg       0.70      0.70      0.69        54\n",
      "\n",
      "Accuracy: 0.7037037037037037\n",
      "MCC = 0.3533767463701098\n",
      "AUC = 0.6623376623376623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#test rfe then LR classifier\n",
    "print('Using 20% as test subset:')\n",
    "newX_train,newX_test = rfe_LR(X_train_20, y_train_20,X_test_20)\n",
    "RFE_LR_y_predicted_20 = LR(newX_train,newX_test,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "newX_train,newX_test = rfe_LR(X_train_40, y_train_40,X_test_40)\n",
    "RFE_LR_y_predicted_40 = LR(newX_train,newX_test,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b2201",
   "metadata": {},
   "source": [
    "### Test on RFc classifier using RFE selected features for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7cd897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_RFc(X_train, y_train,X_test):\n",
    "    min_features_to_select = 1\n",
    "\n",
    "    #run RFE on current train subset\n",
    "    clf = RandomForestClassifier()\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train_40.shape[1])\n",
    "\n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae8e041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "We kept 11 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.48        10\n",
      "           1       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.57      0.57      0.57        27\n",
      "weighted avg       0.60      0.59      0.60        27\n",
      "\n",
      "Accuracy: 0.5925925925925926\n",
      "MCC = 0.1445304031446501\n",
      "AUC = 0.5735294117647058\n",
      "Using 40% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_15280\\1229368516.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 221 features out of the 320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40        21\n",
      "           1       0.65      0.79      0.71        33\n",
      "\n",
      "    accuracy                           0.61        54\n",
      "   macro avg       0.57      0.56      0.56        54\n",
      "weighted avg       0.59      0.61      0.59        54\n",
      "\n",
      "Accuracy: 0.6111111111111112\n",
      "MCC = 0.1348399724926484\n",
      "AUC = 0.5606060606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_15280\\1229368516.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "#test rfe then RFc classifier\n",
    "print('Using 20% as test subset:')\n",
    "newX_train,newX_test = rfe_RFc(X_train_20, y_train_20,X_test_20)\n",
    "RFE_RF_y_predicted_20 = RFc(newX_train,newX_test,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "newX_train,newX_test = rfe_RFc(X_train_40, y_train_40,X_test_40)\n",
    "RFE_RF_y_predicted_40 = RFc(newX_train,newX_test,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1077158",
   "metadata": {},
   "source": [
    "### FORWARD ORDER ->  Greedy Feature Selection Algorithm on XGBoost Classifier for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54907f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_select_XGB(X_train, y_train):\n",
    "    \n",
    "    acc_imp = 0  \n",
    "    last_best_acc=0\n",
    "    features_selected=[]\n",
    "    best_features = []\n",
    "    no_imp_counter=0\n",
    "    \n",
    "    while no_imp_counter<20:\n",
    "        accuracies = []\n",
    "        for i in range(len(X_train)):   \n",
    "            curr_X_train = X_train.iloc[:,i]\n",
    "            for j in range(len(features_selected)):\n",
    "                curr_X_train = pd.concat([curr_X_train, features_selected[j]],axis=1)\n",
    "            fs_X_train, fs_X_test, fs_y_train, fs_y_test = train_test_split(curr_X_train, y_train, test_size = 0.80, random_state = 97,stratify=y_train)\n",
    "            \n",
    "            clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False)\n",
    "            clf.fit(fs_X_train, fs_y_train)\n",
    "            y_predicted = clf.predict(fs_X_test)\n",
    "            accuracies.append(accuracy_score(fs_y_test, y_predicted))\n",
    "        \n",
    "        best_feature_idx=np.argmax(accuracies) \n",
    "        print('new best feature added =',X_train.iloc[:,best_feature_idx].name)\n",
    "        features_selected.append(X_train.iloc[:,best_feature_idx])\n",
    "        X_train.drop(X_train.columns[best_feature_idx],axis=1,inplace=True)\n",
    "        \n",
    "        curr_acc=accuracies[best_feature_idx]\n",
    "        print('new acc =',curr_acc)\n",
    "        if curr_acc>last_best_acc:\n",
    "            acc_imp = curr_acc-last_best_acc\n",
    "            last_best_acc = curr_acc\n",
    "            best_features=features_selected.copy()\n",
    "            no_imp_counter=0\n",
    "            print('improvement of',acc_imp)\n",
    "        else:\n",
    "            no_imp_counter+=1\n",
    "            print('no improvement for',no_imp_counter,'times')\n",
    "\n",
    "    \n",
    "    print('-> last best acc on training set =',last_best_acc)\n",
    "    \n",
    "    best_features_names = []\n",
    "    for i in best_features:\n",
    "        best_features_names.append(i.name)\n",
    "\n",
    "    return best_features_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2ff691",
   "metadata": {},
   "source": [
    "### forward selection with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3655e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Forward feature selection:\n",
      "new best feature added = CCKN.NLQNLDPSHR\n",
      "new acc = 0.6551724137931034\n",
      "improvement of 0.6551724137931034\n",
      "new best feature added = ALDOA.QLLLTADDR\n",
      "new acc = 0.6896551724137931\n",
      "improvement of 0.034482758620689724\n",
      "new best feature added = B3GN1.YEAAVPDPR\n",
      "new acc = 0.735632183908046\n",
      "improvement of 0.04597701149425282\n",
      "new best feature added = CO3.IHWESASLLR\n",
      "new acc = 0.7701149425287356\n",
      "improvement of 0.03448275862068961\n",
      "new best feature added = BASP1.ETPAATEAPSSTPK\n",
      "new acc = 0.7816091954022989\n",
      "improvement of 0.011494252873563315\n",
      "new best feature added = CNTP2.YSSSDWVTQYR\n",
      "new acc = 0.7931034482758621\n",
      "improvement of 0.011494252873563204\n",
      "new best feature added = AATC.LALGDDSPALK\n",
      "new acc = 0.7816091954022989\n",
      "no improvement for 1 times\n",
      "new best feature added = CA2D1.FVVTDGGITR\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 2 times\n",
      "new best feature added = B3GN1.EPGEFALLR\n",
      "new acc = 0.8045977011494253\n",
      "improvement of 0.011494252873563204\n",
      "new best feature added = APLP2.HYQHVLAVDPEK\n",
      "new acc = 0.7931034482758621\n",
      "no improvement for 1 times\n",
      "new best feature added = CMGA.YPGPQAEGDSEGLSQGLVDR\n",
      "new acc = 0.7931034482758621\n",
      "no improvement for 2 times\n",
      "new best feature added = CNTN1.TTKPYPADIVVQFK\n",
      "new acc = 0.7931034482758621\n",
      "no improvement for 3 times\n",
      "new best feature added = CNTN2.IIVQAQPEWLK\n",
      "new acc = 0.7931034482758621\n",
      "no improvement for 4 times\n",
      "new best feature added = CNTN2.TTGPGGDGIPAEVHIVR\n",
      "new acc = 0.7931034482758621\n",
      "no improvement for 5 times\n",
      "new best feature added = APLP2.WYFDLSK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 6 times\n",
      "new best feature added = AMD.IVQFSPSGK\n",
      "new acc = 0.7816091954022989\n",
      "no improvement for 7 times\n",
      "new best feature added = AMD.NGQWTLIGR\n",
      "new acc = 0.7816091954022989\n",
      "no improvement for 8 times\n",
      "new best feature added = CMGA.SGEATDGARPQALPEPMQESK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 9 times\n",
      "new best feature added = CA2D1.TASGVNQLVDIYEK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 10 times\n",
      "new best feature added = CNTP2.HELQHPIIAR\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 11 times\n",
      "new best feature added = CSTN1.GNLAGLTLR\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 12 times\n",
      "new best feature added = CSTN1.IHGQNVPFDAVVVDK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 13 times\n",
      "new best feature added = BTD.SHLIIAQVAK\n",
      "new acc = 0.7586206896551724\n",
      "no improvement for 14 times\n",
      "new best feature added = CATL1.VFQEPLFYEAPR\n",
      "new acc = 0.7586206896551724\n",
      "no improvement for 15 times\n",
      "new best feature added = CMGA.SGELEQEEER\n",
      "new acc = 0.7471264367816092\n",
      "no improvement for 16 times\n",
      "new best feature added = AACT.ADLSGITGAR\n",
      "new acc = 0.7586206896551724\n",
      "no improvement for 17 times\n",
      "new best feature added = A1AT.SVLGQLGITK\n",
      "new acc = 0.8160919540229885\n",
      "improvement of 0.011494252873563204\n",
      "new best feature added = A4.WYFDVTEGK\n",
      "new acc = 0.8160919540229885\n",
      "no improvement for 1 times\n",
      "new best feature added = CA2D1.IKPVFIEDANFGR\n",
      "new acc = 0.8160919540229885\n",
      "no improvement for 2 times\n",
      "new best feature added = APOE.LGPLVEQGR\n",
      "new acc = 0.7816091954022989\n",
      "no improvement for 3 times\n",
      "new best feature added = AATM.FVTVQTISGTGALR\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 4 times\n",
      "new best feature added = A1BG.NGVAQEPVHLDSPAIK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 5 times\n",
      "new best feature added = APOE.AATVGSLAGQPLQER\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 6 times\n",
      "new best feature added = CNTN1.DGEYVVEVR\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 7 times\n",
      "new best feature added = CO2.HAIILLTDGK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 8 times\n",
      "new best feature added = APOE.LAVYQAGAR\n",
      "new acc = 0.7586206896551724\n",
      "no improvement for 9 times\n",
      "new best feature added = EXTL2.VIVVWNNIGEK\n",
      "new acc = 0.7471264367816092\n",
      "no improvement for 10 times\n",
      "new best feature added = CLUS.SGSGLVGR\n",
      "new acc = 0.7586206896551724\n",
      "no improvement for 11 times\n",
      "new best feature added = CAD13.DIQGSLQDIFK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 12 times\n",
      "new best feature added = AMD.IPVDEEAFVIDFKPR\n",
      "new acc = 0.7586206896551724\n",
      "no improvement for 13 times\n",
      "new best feature added = CADM3.EGSVPPLK\n",
      "new acc = 0.7586206896551724\n",
      "no improvement for 14 times\n",
      "new best feature added = APOB.IAELSATAQEIIK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 15 times\n",
      "new best feature added = CNTN2.VIASNILGTGEPSGPSSK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 16 times\n",
      "new best feature added = FAM3C.SPFEQHIK\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 17 times\n",
      "new best feature added = FETUA.AHYDLR\n",
      "new acc = 0.7701149425287356\n",
      "no improvement for 18 times\n",
      "new best feature added = APOD.VLNQELR\n",
      "new acc = 0.7471264367816092\n",
      "no improvement for 19 times\n",
      "new best feature added = APOB.SVSLPSLDPASAK\n",
      "new acc = 0.7586206896551724\n",
      "no improvement for 20 times\n",
      "-> last best acc on training set = 0.8160919540229885\n",
      "We kept 27 features out of the 320\n",
      "2) XGB with forward feature selection\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.70      0.58        10\n",
      "           1       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.63      0.64      0.62        27\n",
      "weighted avg       0.67      0.63      0.64        27\n",
      "\n",
      "Accuracy: 0.6296296296296297\n",
      "MCC = 0.27857101420419017\n",
      "AUC = 0.6441176470588236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3276\\2171492240.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  newX_test = X_test_20[(newX_train.columns) & (X_test_20.columns)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.10399897, 0.99735767, 0.6314105 , 0.49959764, 0.9893807 ,\n",
       "       0.9230327 , 0.01280146, 0.05296926, 0.31103373, 0.43684182,\n",
       "       0.25503823, 0.9917041 , 0.06190662, 0.02566956, 0.8606966 ,\n",
       "       0.8885741 , 0.550077  , 0.70379966, 0.8080717 , 0.58586234,\n",
       "       0.5093064 , 0.2854946 , 0.29883456, 0.43967277, 0.94519717,\n",
       "       0.18139008, 0.27002347], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test tuning XGB hyperparameters with selected features from forward selection\n",
    "print('1) Forward feature selection:')\n",
    "fs_best_features = forward_select_XGB(X_train_20.copy(), y_train_20)\n",
    "newX_train = X_train_20.loc[:,fs_best_features]\n",
    "newX_test = X_test_20[(newX_train.columns) & (X_test_20.columns)]\n",
    "print('We kept',newX_train.shape[1],'features out of the',X_train_20.shape[1])\n",
    "print('2) XGB with forward feature selection')\n",
    "XGB_class(newX_train,newX_test,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edbff0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Forward feature selection:\n",
      "new best feature added = A1BG.SGLSTGWTQLSK\n",
      "new acc = 0.676923076923077\n",
      "improvement of 0.676923076923077\n",
      "new best feature added = CAD13.DIQGSLQDIFK\n",
      "new acc = 0.7230769230769231\n",
      "improvement of 0.0461538461538461\n",
      "new best feature added = AACT.EIGELYLPK\n",
      "new acc = 0.7538461538461538\n",
      "improvement of 0.03076923076923077\n",
      "new best feature added = AACT.NLAVSQVVHK\n",
      "new acc = 0.7538461538461538\n",
      "no improvement for 1 times\n",
      "new best feature added = ALDOA.QLLLTADDR\n",
      "new acc = 0.7538461538461538\n",
      "no improvement for 2 times\n",
      "new best feature added = AATC.NLDYVATSIHEAVTK\n",
      "new acc = 0.7692307692307693\n",
      "improvement of 0.015384615384615441\n",
      "new best feature added = APOE.LGADMEDVR\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 1 times\n",
      "new best feature added = APLP2.HYQHVLAVDPEK\n",
      "new acc = 0.7846153846153846\n",
      "improvement of 0.01538461538461533\n",
      "new best feature added = APOE.AATVGSLAGQPLQER\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 1 times\n",
      "new best feature added = AATM.FVTVQTISGTGALR\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 2 times\n",
      "new best feature added = CATL1.VFQEPLFYEAPR\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 3 times\n",
      "new best feature added = CATA.LFAYPDTHR\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 4 times\n",
      "new best feature added = CNDP1.WNYIEGTK\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 5 times\n",
      "new best feature added = AMD.IVQFSPSGK\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 6 times\n",
      "new best feature added = CADM3.EGSVPPLK\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 7 times\n",
      "new best feature added = AATC.LALGDDSPALK\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 8 times\n",
      "new best feature added = B3GN1.TALASGGVLDASGDYR\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 9 times\n",
      "new best feature added = APLP2.WYFDLSK\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 10 times\n",
      "new best feature added = A4.LVFFAEDVGSNK\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 11 times\n",
      "new best feature added = CADM3.SLVTVLGIPQKPIITGYK\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 12 times\n",
      "new best feature added = BTD.SHLIIAQVAK\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 13 times\n",
      "new best feature added = CO2.HAIILLTDGK\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 14 times\n",
      "new best feature added = C1QB.VPGLYYFTYHASSR\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 15 times\n",
      "new best feature added = CNTN1.TTKPYPADIVVQFK\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 16 times\n",
      "new best feature added = CO2.SSGQWQTPGATR\n",
      "new acc = 0.7846153846153846\n",
      "no improvement for 17 times\n",
      "new best feature added = CATD.LVDQNIFSFYLSR\n",
      "new acc = 0.7692307692307693\n",
      "no improvement for 18 times\n",
      "new best feature added = CLUS.VTTVASHTSDSDVPSGVTEVVVK\n",
      "new acc = 0.7538461538461538\n",
      "no improvement for 19 times\n",
      "new best feature added = B2MG.VNHVTLSQPK\n",
      "new acc = 0.7538461538461538\n",
      "no improvement for 20 times\n",
      "-> last best acc on training set = 0.7846153846153846\n",
      "We kept 8 features out of the 320\n",
      "2) XGB with forward feature selection\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.43      0.49        21\n",
      "           1       0.68      0.79      0.73        33\n",
      "\n",
      "    accuracy                           0.65        54\n",
      "   macro avg       0.62      0.61      0.61        54\n",
      "weighted avg       0.64      0.65      0.64        54\n",
      "\n",
      "Accuracy: 0.6481481481481481\n",
      "MCC = 0.23108558332704238\n",
      "AUC = 0.6082251082251082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3276\\2029477957.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  newX_test = X_test_40[(newX_train.columns) & (X_test_40.columns)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.22983837, 0.90224224, 0.9777076 , 0.8337252 , 0.78335315,\n",
       "       0.98989546, 0.9824309 , 0.41167808, 0.5127063 , 0.9808028 ,\n",
       "       0.3011225 , 0.76395535, 0.9314521 , 0.9593564 , 0.98428106,\n",
       "       0.6887277 , 0.98968935, 0.9948872 , 0.9235701 , 0.48043504,\n",
       "       0.75354993, 0.96493727, 0.992304  , 0.04820057, 0.04855882,\n",
       "       0.24267237, 0.86527187, 0.75112355, 0.98698723, 0.8239646 ,\n",
       "       0.99333656, 0.5081772 , 0.8393064 , 0.9640621 , 0.31898946,\n",
       "       0.95576525, 0.99959475, 0.09570237, 0.00716321, 0.8617119 ,\n",
       "       0.13012321, 0.9332173 , 0.37570825, 0.05872868, 0.25718832,\n",
       "       0.10341216, 0.8077406 , 0.94491374, 0.7718307 , 0.670845  ,\n",
       "       0.9841717 , 0.9722015 , 0.80106187, 0.01985686], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test tuning XGB hyperparameters with selected features from forward selection\n",
    "print('1) Forward feature selection:')\n",
    "fs_best_features = forward_select_XGB(X_train_40.copy(), y_train_40)\n",
    "newX_train = X_train_40.loc[:,fs_best_features]\n",
    "newX_test = X_test_40[(newX_train.columns) & (X_test_40.columns)]\n",
    "print('We kept',newX_train.shape[1],'features out of the',X_train_40.shape[1])\n",
    "print('2) XGB with forward feature selection')\n",
    "XGB_class(newX_train,newX_test,y_train_40,y_test_40,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f8f54",
   "metadata": {},
   "source": [
    "### Plot AUC-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8d6c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(y_tests,y_predicted,models_name,title):  \n",
    "    if len(y_predicted)>2:  \n",
    "        #there are 4 diff colors in max\n",
    "        colors = [\"red\", \"blue\", \"green\", \"orange\"]\n",
    "            \n",
    "        for i in range(int(len(y_predicted)/2)):\n",
    "            fpr, tpr, _ = metrics.roc_curve(y_tests[i],  y_predicted[i])\n",
    "            #create ROC curve\n",
    "            plt.plot(fpr, tpr, linestyle='-',color=colors[i])\n",
    "\n",
    "        counter=0\n",
    "        for i in range(int(len(y_predicted)/2),int(len(y_predicted))):\n",
    "            fpr, tpr, _ = metrics.roc_curve(y_tests[i],  y_predicted[i])\n",
    "            #create ROC curve\n",
    "            plt.plot(fpr, tpr, linestyle='--',color=colors[counter])\n",
    "            counter+=1\n",
    "    \n",
    "    else:\n",
    "        for i in range(int(len(y_predicted))):\n",
    "            fpr, tpr, _ = metrics.roc_curve(y_tests[i],  y_predicted[i])\n",
    "            #create ROC curve\n",
    "            plt.plot(fpr, tpr, linestyle='-')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.legend(models_name)\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42fb5606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3304\\57784247.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_tests = np.array([y_test_20,y_test_40])\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3304\\57784247.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_preds = np.array([RFE_XGB_y_predicted_20,RFE_SVM_y_predicted_40])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_tests = np.array([y_test_20,y_test_40])\n",
    "y_preds = np.array([RFE_XGB_y_predicted_20,RFE_SVM_y_predicted_40])\n",
    "models_name=np.array(['RFE_XGBc 20%','RFE_SVM 40%'])\n",
    "title = 'ROC curve of stronger models using RFE'\n",
    "roc(y_tests,y_preds,models_name,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6b2b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3304\\3752811329.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_tests = np.array([y_test_20,y_test_20,y_test_20,y_test_20,y_test_40,y_test_40,y_test_40,y_test_40])\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3304\\3752811329.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_preds = np.array([XGBc_y_predicted_20,SVM_y_predicted_20,RFc_y_predicted_20,LR_y_predicted_20,XGBc_y_predicted_40,SVM_y_predicted_40,RFc_y_predicted_40,LR_y_predicted_40])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABsQElEQVR4nO2dZ3gVRReA30mBUEIKRYTQSSiBEEgQgiAgvYsgEJSiCNKkVwHpiooaUESaH4ggIIoUaYKGIr0ECER6lQ4hEBJIm+/Hbi7puUnuzU2Z93nmubs7szNn9u7u2WnnCCklCoVCoVAkh5WlBVAoFApF1kYpCoVCoVCkiFIUCoVCoUgRpSgUCoVCkSJKUSgUCoUiRZSiUCgUCkWKKEWRCxBCDBBC3BFChAohCqfhvC1CiF5mkkkKISqaI+/0IoQoq8tlY0Ta3kKIvWaU5bQQolEK8f5CiPfNVb5eRiMhxA1jZcqNpOWeyc5kW0UhhLgihAjXX363hRBLhRAFE6SpJ4T4SwjxRAgRIoTYKISomiBNISGEnxDimp7XBX2/SObWyDwIIWyBr4DmUsqCUsoHxp4rpWwlpVxmPukUySGldJdS+gMIIaYIIX6ysEhplkl/iW4WQgTrz+i3cV+oQogmQoh/hRBhQoi/hRBlksjjnBDCTQgxWggRqD/Ll4UQo5Mo6289r3+FEE1NVO0MI4ToJoQIEkI8FUJcFEI0iBNn9DWIs59HP+dGgnRmuwbZVlHotJNSFgQ8gZrA+NgIIYQPsB1YD5QAygEngH+EEOX1NHmAnYA70BIoBNQDHgCvmEvoTP76eAmwA05nYpkKBcB3wF3gZbRntCEwEED/EPsNmAQ4A0eA1XFPFkJUAKyklOcAAfQEnNCe1cFCiG5xkv8MHAcKAxOAtUKIouaqmLEIIZoBnwHvAvbAa8AlPS6t1yCW0WjXNSHmuwZSymwZgCtA0zj7nwN/xNnfA3yXxHlbgB/17feBO0DBNJTrDvwJPNTP/Ug/vhSYESddI+BGAnnHAieB58BEYG2CvOcAc/VtB2AJcAv4D5gBWCcjU17AD7ipBz/9mBvwFJBAKPBXEufaAT+hKcdHwGHgJT3OH3hf3+4N/AN8rae7hKZUewPX0W7cXnHyXQp8r1+rJ8AuoEyceAlUjCP/bOCafk2/B/IlU9e0yuEA/AjcA67q191Kj7PWy72v5zNIl8smtf9AL2+vvi10ee4CIfp/XC0J2RsDp+Ls7wAOxdnfC7wR9/5GeylGAJH6f3gizn8zXb8WT9A+iookc82KAJv06/UQ7dmwilPOeOAMEAz8D7BL4R5OVqYkyg0CWsfZ/wJYoG/3A/bFiSsAhAOV4xwbgv48JJH3XOAbfdsN7ZmyT/D890/m3FeA/fr1uAV8C+RJcG/2B87r12QeIIy5Z5Ioax/QJ5m4NF8DtA/eIKBVgv8mTdcgrSG7tygAEEK4oF24C/p+frSXxy9JJF8DNNO3mwJbpZShRpZjj/Zwb0VrpVREa5EYiy/QBnAElgOthRCF9LytgS7ASj3tMiBKL6Mm0BxNsSXFBKAu2ldbDbQHYaLUvkLc9TSOUsrXkzi3F9oLsRTal0h/tJs1KeqgvQQL63KuAmrrMr4DfJug++9ttJdZESAAWJFMvp+h3eieel4lgY+TSZtWOb7R61ce7Yu2J9rXHUBfoC3a9fUGOicox9j/oDnal6Ib2n/bFU3xJmQ/UFEIUURvVVYDXIQQ9kKIfIAX2sNtQEq5FfgEWC21rsMacaK763UpBuQBRiVRJsBI4AZQFK2F+RHayy2Wt4EWQAW9DhOTyccYmeIyB+gmhMgvhCiJ9oxu1ePc0Vr4sXk+BS7y4n4FaA38kTBTIYQAGvCilewOXJJSPomT7ESCvOISDQxHuy99gCboLZ04tEW7p2qgPZct9OOp3TNx5bTW0xTVu7Rv6N1v+eLIndZr8A3a/5fwGU3rNUgT2V1R/C6EeMKLL8nJ+nFntLrdSuKcW2g3CGgvmqTSJEdb4LaU8ksp5TMp5RMp5cE0nD9XSnldShkupbwKHAPe0ONeB8KklAeEEC+hPVTDpJRPpZR30b5YuyWZq/agT5NS3pVS3gOmAj2MlCkS7TpUlFJGSymPSikfJ5P2spTyf1LKaLQmcim93OdSyu1oX5lxB6j/kFLullI+R1NmPkKIUnEz1B/6vsBwKeVD/Ub/JIW6Gi2H/qB2Bcbr/9UV4Ms416YL4Kf/Jw+BT+PIlZb/IBKtW6Ey2pdnkJQy0X0lpXyG1r3wGtoL5CRaK+JVNEV/XqZhDAn4n5TynJQyHO0DyDOZdJFo3T9lpJSRUso9Uv/k1Pk2zjWYifZBYwp2ob2oHqMpqiPA73pcQbTWV1xC0K5j7MdebT2PhExBe77/Z0xeCdHv8QNSyij9nliA9hERl1lSykdSymvA37y4tsneM0nwEmCLpkwa8KKLPFYRp+kaCCE6orVc1iVRVpquQVrJ7oriDSmlPVoTuTIvFEAwEIP2cCTkZbRmI2hffUmlSY5SaBo/vVxPsL+SFw9ld160Jsqg3WC3hBCPhBCP0G7mYsnkWwKtWyWWq/oxY1gObANWCSFuCiE+1wfAk+JOnO1wACllwmNxWxSG+uqttodJyFUUyA8cjVPXrfrx5DBWjiJoX9oJr01JfbsE8f+TuOmM/g+klH+hdV/MA+4IIRbGthSTYBfa/fqavu2P9pJqSNIvxZS4HWc7jPjXPi5foLW2twshLgkhxiWIT3gNjL13kkUIYYV2X/2G1qVSBG184TM9SSjamGBcCqF1o4H2lb9PV65x8x2M1ipso3+AGJNXQtnchBCb9AH2x2gfJgknryR3bVO6ZxIS+9X/jZTylpTyPtrEktZGym24BkKIAmjd6x8mU1aarkFaye6KAgAp5S60PvHZ+v5TtGb+W0kk78KL7qIdQAv9TzCG62jN86R4ivbCi6V4UqIm2P8FaKR3nXXkhaK4jtbfWERK6aiHQlLK5JqRN9FebLGU1o+liv6FOVVKWRWtu64t2oNoCgytB70ryDkJue6jPVDucerqILVJChnlPtrXdMJr85++fSuujHpcLGn6D6SUc6WUXmhf0G5oA45JkVBR7CJ1RZEhE896a2qklLI80A4YIYRoEidJwmtgzL2TmkzOer7f6i29B2gtgNiX5Gm0bh0A9GewAi+6kxJ1Owkh3gPGAU2klHFn/JwGyutdw7HUIPkJHPOBfwFXKWUhtK4ckUp9YknpnomHlDIYrSWV3LVKyzVwBcoCe4QQt9EU8Mu6sitL2q9BmsgRikLHD2gmhPDU98cBvYQQQ/Q+YCchxAy0PsmpeprlaC+EX4UQlYUQVkKIwkKIj4QQrRMWgDYgWFwIMUwIkVfPt44eF4A25uAshCgODEtNYL2byB/tAbospQzSj99CG5z8UmjTd62EEBWEEAmbx7H8DEwUQhTVZ1J8jDZAnSpCiMZCiOp6N81jtBdrtDHnGkFrIUR9fXbZdOCglDJeq0pKGQMsAr4WQhTTZSophGiROLu0oXdNrQFm6v9VGWAEL67NGmCIEMJFCOGEds/Enmv0fyCEqC2EqKO3xJ4Cz0j+Gu4DKqGNIx2SUp5GU2R1gN3JnHMHKKt/pacZIURbIURFvZvvsS5bXPkG6dfAGe2luTqpfNIik/71fBkYIISwEUI4oo2HxfbJrwOqCSE6CSHs0O7Zk1LKf/X4VsDmOHV4G+3Lv5mU8lKCss6hPX+ThRB2eheNB/BrMrLbo12HUCFEZWCAEfWNJdl7Jhn+B3wohCimpx+G9h6BtF2DQDQF5amH2Ik4nsD1dFyDNJFjFIX+0v0RbaoZUsq9aANQb6J9BVxF6x+sL6U8r6d5jjag/S/a7JzHwCG0ZmiisQe9/7wZ2lfZbbRZEY316OVoD8EVtBeMMQ8baK2IprxoTcTSE63bJHY2ylqS7yabgdb/exI4hTb2McPI8ovreT9Gm02xCyOVjBGsRBs3eog2UPt2MunGonWNHNC7AnagvUxNwYdoL+9LaOMBK4Ef9LhFaN0jJ9Cu2W8JzjX2Pyik5xWMdp89QG/dJkRv7R4DTkspI/TD+4Gr+jhIUsROyngghDiWXEVTwBXtmobqZX0n9fUQOivR7tlLejDm3jFGpjfRZkjdQ/t/o9AGkWOf105oYyLBaIqyG4AQohoQqo8PxDIDbSztsNDWO4UKIb6PE98NbdwnGJgFdNbLSIpRaF29T9D+N2OfVUj9nknIdLSZhOfQnq/jaHVO0zXQx1Nuxwa0ZypG349V+mm5BmkidsqXQmFShBBL0abvpTiDRmFZhBBX0KZA77C0LLEIIcagdfmNsbQsliKrXYMcvexcoVBkS64AGy0thIW5Qha6BkpRKBSKLIWUco2lZbA0We0aqK4nhUKhUKRIjhnMVigUCoV5yHZdT0WKFJFly5a1tBgKhUKRrTh69Oh9KWW6jARmO0VRtmxZjhw5YmkxFAqFIlshhEhpFXmKqK4nhUKhUKSIUhQKhUKhSBGlKBQKhUKRIkpRKBQKhSJFlKJQKBQKRYooRaFQKBSKFDGbohBC/CCEuCuECEwmXggh5grNReBJIUQtc8miUCgUivRjznUUS9G8fv2YTHwrNPPHrmjmdefrvwqFQpGI51HPiZExhv28NnmxElZExUQRGR2ZKH1sfGR0JFExUYni7WzsEEKkGh8RHUF0TGL3IvlsNdfXqcUnlBtACIGdjZ1R8c+inpHQ1JKVsCKvTd50x6cVsykKKeVu3fNScnQAftR99x4QQjgKIV5OytewQmEMC48uZOWphG49FMZw6xbcuZN6OksgieFZ/gtE5I3/aigY4o11TAGe573Bs/yJPRTbP6qDlbTjmd1Vnue7kig+z4455PP6jfB8l4iwS+ilGPLu/Aa7WmsJz3eeCLsETv+i8mK391Py1lhPmN05IvMleG2FO5Lv2FjyVN3KU7uzROW7HT/+cUnyBfUlj9vfhOYLItougSuSB67kv9IJ2/L7eZIvkBi7BK7Ub3tS4M7r2JQ+ypP8J4jJ+yh+/PV6FHjsiU2J04Q8OwwvhyWqX1qw5MrsksT3PXtDP5ZIUQgh+gH9AEqXTtbzoCKXs/LUSgJuB+BZ3NPSomQ77tyB0FAoaAoHtCYm2jqUiDy3sX1eHOvofIbjQuYBwDrKAbuwconOE1J7vdlEOiJk/Pjnge2IONyDfF6/YRvpTFRgO2RMgtehFPr5hYk82Tl+XIy1YdPmeXGiTiXwuhyV90V8uAvRp7rEj48oqHlkB2xDyxFzslv8+HAnKKi5BLd9XImIk97x458WA+eHWnxwNSKuJei5f1ISWeQC4bsuQEAYn7/rxBiCSS+WVBRJ+ahNsn0kpVwILATw9vZW5m4VyeJZ3BP/3v6WFiPb0aiR9uvvb0kp4hMWGUZ+W80N/fkH53Et7GqyvBs1AuqCv59/KikHpRI/PJX41DylTk4lPn3s3LmTvn2/5/Ll/xg0aBD98ywmIx6QLDnr6QbxnZS7YJxTd4VCkcMJuB1ApW8r8VuQ5mnUlEoipzNmzBiaNm2KjY0Nu3fv5ttvv8W+hF2G8rSkotgA9NRnP9UFQtT4hEKh2HJ+Cw3+1wCBwNVZKQhjiR2wrlmzJmPHjuXEiRM0aNBAi3zwPEN5m63rSQjxM9AIKCKEuIHWxrIFkFJ+D2wGWqM5XQ8D3jWXLAqFInvw/ZHvGbx5MB4vebCp+yZK2JcwSzmFC5slW4tw584dPvzwQ+rXr8+QIUPw9fXF19c3fqKCzzJUhjlnPfmmEi9JvQNQoVDkEvZe28uAPwbQxrUNqzqvomAe842s//qr2bLONKSULF++nGHDhvH06VPq1q1rtrKynT8KhUKRM6lfuj6/vPULb1R+Axsr9WpKiWvXrvHBBx+wdetW6tWrx5IlS6hcubLZylMmPBQKhcW49/QeLX5qwYnbJwDoXLVzpiiJ8eO1kF25fPkye/fuZe7cuezZs8esSgJUi0KhUFiIs/fP0npla24+ucm1kGvUKF4j08revz/TijIZZ8+exd/fnw8++ICGDRty7do1nJycMqVs1aJQKBSZzu6ru/FZ4sOT50/4u9fftKvUztIiZVmioqKYNWsWNWrUYMKECTx69AggbUriab7U06SAUhQKhSJT2X99P82WN6NYgWIceP8AdV3MNwib3QkICKBOnTqMHz+eNm3aEBgYiKOjY9ozcs6TITlU15NCochUvEt4M7zucMa8OgbnfM6WFifL8ujRIxo0aECBAgVYu3YtnTp1Sn9m9zK2jkK1KBQKhdmJjI5kws4J3Ht6D1trW2Y1nWVRJeHiooWsSFBQEACOjo6sWrWKM2fOZExJABTK2DoKpSgUCoVZCXkWQpuVbfhk7ydsOLvB0uIA8NNPWshKhIaGMmTIENzd3dmwQbtObdq0wdnZ8q0u1fWkUCjMxrWQa7RZ2YZ/7//LD+1/4N2aygBDUmzfvp1+/fpx7do1Bg8ezOuvv25pkeKhFIVCoTALp+6covlPzQmLDGPr21tpUr6JpUUyMGyY9uvnZ0kpNEaOHMlXX31F5cqV2bNnD6+++qqlRUqEUhQKRSYQGhFKl1+6EPxM8wmwuvNqSjuUZuWplXxz6JtE6Td020DRAkVZfGwxS44vSRS/o8cOCuQpwNyDc/k58OdE8fv7aAsFZu2dxfqz6+PF5bfNz86eOwH4+O+P+fPSn5zW3Rn4LIEi+Yuw0XcjAKO2j+Kf6//EO79UoVKseWsNAAP/GMjx28fjxVcqXImlbyyleMHiVC1alTkt51CtWLVUr1FqjB+feP2Di8uLLqRhwyAgIH68mxssXKht9+sH585p2zUKLOTdxivhqCd4+WkH970DYTfiZ1DEBzw/1bb3dILnCRwIvdQEqk/Str8oCiKBp70C9WHAJm17tmO8KCklwqkVtWu/wUcjhzGp8A/Y7W8DcetYrDP0XAw3z8LKJByAluwFvnPgwkH4vUXi+AofQsfpECZIxouDUShFoVBkApeCL7HlwhZqvFSDlwq+hJXQhgfzWOehUN5CidLHxue1zptkvBCaOxc7G7sk42NJKj6fzYs59flt81MobyFsdE+ehfISz8ZSbHxc4sYXsC2QKL6AbQEAihYoalBIWY13G6+kyssBgGeml337cQyDfw+nQTkbhraDbt260a11U1j4P/MVapUPzfZq+hAZ9aWa2Xh7e8sjR45YWgxFFqTR0kYAWdJx0ck7J6nxfQ1+7fIrb1Z509LiJCIrOi4yKzsaab9N/TOtSCkly5YtY8SIEYSFhTFr1iyGxfaBmZvZjojRIUellN6pJ06MmvWkUGQCVsJK+3JXxu7SRadOWsiyTJ+uhWS4evUqLVu25N1338Xd3Z0TJ05knpIwAequVSgygWrFqhEyLsTSYmRbHjxIPU2asHczbX479S62SZOSjL569Sr79+9n3rx59O/fHyur7PWNrhSFQqHIfdRZaPYigoKC8Pf3Z8CAAbz22mtcu3YtfeY3sgDZS60pFNmUq4+u0m1tNw79d8jSoijMTGRkJDNnzsTT05PJkycTEqK1JLOrkgClKBSKTCHkeQirT6/mxuMbqSdWmJ+D/bRgYo4dO0bt2rWZOHEib7zxBqdOncLBwcHk5WQ2qutJoVBkeZqYeq3ek3Omza9wYYIjInjttdewt7dn3bp1vPHGG6Ytw4IoRaFQKLI8yYwRZwnOnDlD1V9/xQn4ZcsW6tatm2kOhTIL1fWkUCgU6eDJkycMGjQonhG/Vq1a5TglAUpRKBSZgo2VDSXsS2BnY2dpUbIlrVppIauwZcsW3N3dmT9/PsOGDaPJrl3Z2wl3KqiuJ4UiE6hatCr/jfjP0mJkW8LDTZyhk2e6Tx0+fDh+fn5UqVKFf/75Bx8fnxdL23MoSlEoFIrcR6whQCOJNXUkhKBu3bpMnDiRiRMnkjdvXjMIl/VQXU8KRSZwOfgybVa2Yd/1fZYWRZFGbt68SceOHZkzZw4AXbt2Zfr06blGSYBSFApFpvAk4gmbz2/mduhtS4uiAM2k+L53UkwipWTJkiVUrVqVbdu2YW1tnUnCZT1U15NCocjytG1r4gwT+p1IwOXLl+nbty87d+6kYcOGLF68mIoVKyZ/QlZ1wG0ilKLIQiw8upCVp1ZaWoxsS8DtADyLe1pajCSJkTGWFiFlbt2EO3eh0TBLS5Iko2I35l9PbCHQygo8PLTtq1chODh+vK0tuLtr25cuwePHMCxU2+/sCHnzQpUq2v6FCxAayo2oKI48fcr3dnb0PXsWq/ff1+LPnYOwBH4dChaEtvmh4t1EzomyDI4ZM0ipup6yECtPrSTgdoClxci2eBb3pHv17pYWIxER0RH03dgXK2FFeafylhYnae7chdBQS0thUc48fco8/Ro0sLHhWqFCfJA3L1a6k6gUqXgXCmfh6/coY2ZEVIsii+FZ3DNLOt5RpJ881nnoXq07kxtOzrItHkD7Ms6inosaOQYA4P/I0zQZxjoumuJPREQEn332GTNmzMDBwYF3zp/HwcGB5P0GppDfu/6mkc8cjDZC4SWDUhQKhZnYeWknVsKKxuUaM9xnuKXFUcSliA8AR44coU+fPpw8eZJu3boxZ86cHGHEz9QoRaFQmIH/Hf8f/Tb1w8fFh0ZlGxl8XCuyCJ6fEhwcTKNSpXBwcGD9+vW0b9/e0lJlWcw6RiGEaCmEOCuEuCCEGJdEvIMQYqMQ4oQQ4rQQ4l1zyqNQmBspJZP+msR7G96jcdnGbPTdqJREFuPUqVNIKXFycmLt2rWcPn1aKYlUMJuiEEJYA/OAVkBVwFcIUTVBskHAGSllDaAR8KUQIo+5ZFIozElkdCQ91vVgxp4ZvF/zff7o/gcOdqobI6sQEhJC//798fDwYMOn9WBPJ1q2bJmtHQplFubsenoFuCClvAQghFgFdADOxEkjAXuhfXIVBB4CUWaUSaEwGzZWNkgkn7z+CePqj1MtCRPSpWXGpnf+8ccffPDBB9y6dYuRI0fSzOMgPDe1I+6cizkVRUngepz9G0CdBGm+BTYANwF7oKuUiSecCyH6Af0ASpcubRZhFYr0cvHhRayEFeWcyvFTx5+UgjADA1c1TPe5Q4cOZe7cuVSrVo3ffvuNV1555cUsJYVRmFNRJPW0yAT7LYAA4HWgAvCnEGKPlPJxvJOkXAgsBPD29k6Yh0JhMQ7cOEC7n9vhVtiNve/uVUrCTITd1xa55S+S36j0UkqklFhZWfHqq6/i7OzM+PHjyZNH9WynB3MOZt8ASsXZd0FrOcTlXeA3qXEBuAxUNqNMCoXJ+PXMrzRe1phCeQvxQ/sflJIwI60rnqN1RePcl/7333906NABPz8/ALp06cLkyZOVksgA5lQUhwFXIUQ5fYC6G1o3U1yuAU0AhBAvAZWAS2aUSaHIMFJKZu+bzVu/vIVncU8O9DlApSKVLC1WrkdKyaJFi6hatSo7duxI2brrS020oDAKs3U9SSmjhBCDgW2ANfCDlPK0EKK/Hv89MB1YKoQ4hdZVNVZKed9cMikUpiAiOoJVgat4s8qbLO+4nHy2+SwtUq7n4sWL9O3bl7///pvGjRuzaNEiKlSokPwJ1bOwE+4siFkX3EkpNwObExz7Ps72TaC5OWVQKExFaIRmy6dgnoLs6LmDQnkLYSWUubSswK1btzh+/DiLFi2iT58+qhvQxKiV2QqFEdx8cpO2K9viUsiF9d3W42jnaGmRcj2BgYH8/ffffPjhh9SvX59r165hb29v3Ml/6w64G28xn4A5CKUoFIpUOHXnFG1WtiH4WTAzX5+pvlYtQO/OLyyzRkRE8Mknn/DJJ5/g7OxMz549cXBwMF5JAESb2gl3zkYpCoUiBf68+Ced1nTCPq89e97dk7Wtv+Zgei+uD8ChQ4d47733OH36NO+88w5ff/21MuKXCShFoVAkw7OoZ/TZ0IdyTuX4o/sfuBTKuV7M2kb8yi2rkoAnBATAsGGJE33yCdSrB/v2wUcfJY738wNPT9ixA2bMSBy/YAFUqgQbN8KXXyaOX74cSpWC1ath/vx4Ufervsaj3r14/fXXcXJyYtOmTbRp0ybN9VSkD6UoFIpksLOxY8vbWyjlUIpCedPknSDb0TRiC9FYA/0tLUoiToSGMmRFR8TOfKxbt446depQqFDO/j+yGkpRKBRJIKUkRsZQpWiVXDOzyZpobcPTM2UHRvXqpRzftKkWkqNdOy0kR9eu0LUrISEhjBo1isWLF+Pufo0iRWrSrFmJFGqQBkqa2gl3ziZ3PAEKRRq5+eQmNtNtWHJsiaVFyZVs3LiRqlWr8sMPPzBmzBicnEw8i77KKC0ojEIpCoVCkaX48MMPad++PYULF+bgwYN89tlnWFurRY2WxOiuJyFEASnlU3MKo1Aocidxjfi99tprFCtWjLFjx5rPPlOs9dim/ubJP4eRqqIQQtQDFqP5iygthKgBfCClHGhu4RQKRebwZb6JACy3QNnXr1+nf//+NG7cmFGjRvHWW28lSjNggAUEUxgwpuvpazRz4A8ApJQngNfMKZRCochcrluX5bp12UwtMyYmhvnz5+Pu7o6/vz8FChRINq0+vq2wEEZ1PUkprydYjRptHnEUiqxBwTwFGV1vNB4veVhalEzBJ3KXvuWZKeVduHCBPn36sHv3bpo2bcrChQspV65csumv6y7QSpVKNonCjBijKK7r3U9SNxc+BAgyr1gKhWVxsHPg82afW1qMTKPr89hOp6GZUt6dO3cIDAxkyZIlvPvuu6maRenRQ/tNaVauwnwYoyj6A3PQXJveALYDanxCkaOJkTE8fv6YfDb5yGuTgl8DhdGcOHECf39/hg4dyquvvsrVq1cpWLCgZYQp3cUy5WZTjBmjqCSlfFtK+ZKUspiU8h2girkFUygsya0nt3D6zIkfT/xoaVGyPc+fP2fSpEl4e3sza9YsQkJCACynJADcBmpBYRTGKIpvjDymUCgU8di/fz81a9ZkxowZdO/encDAwKxhxC8qTAsKo0i260kI4QPUA4oKIUbEiSqE5rFOoVAokuXhw4c0a9aMwoULs2XLFlq2bGlpkV7g31r7VesojCKlMYo8aGsnbIC4ht4fA53NKZRCochcZubXrL3+YoK8jh8/jqenJ87Ozvz+++/UqVMnbb4ikmDkSBMIpkg3ySoKKeUuYJcQYqmU8momyqRQKDKZe1bFM5xHcHAwo0aN4ocffmDdunW88cYbNE3JOGAaSMmGoML8GDPrKUwI8QXgDtjFHpRSvm42qRQKC2Of155pjabhVcLL0qJkCo0jtulbnuk6f926dQwcOJB79+4xfvx4k3cznT2r/VaqZNJsFUZijKJYAawG2qJNle0F3DOnUIrcR4yMSfJ4rInvjMRLKZHINMUXzFOQia9NzDVuTztExHY6jU3zuQMHDmT+/Pl4enryxx9/UKtWLdMKB3zwgfar1lFYBmMURWEp5RIhxNA43VG7Uj1LkXZu3YI7d6BRI0tLYnaOF3zCn87BjLlWGoDKdQ5xPn98P8Zt7zuz8VR1AErW28/tvBHx4n3vFGPlGW2mdqEGe3hqE19Z9PvvZRaccwMk1o13J5Jh5DUXZl+sQKh1FIVe+ydR/JTLZZi8IwpCQ+NH5M8Pbm7a9rlzEJZg9kzBglCxorYdFATPnwNwM6IwdyOcOG3jwSK7IQBMfToSBxkS7/SjNq+w3K4fAJ89HURe+Txe/H7b11idtycAfqHvJ5L7b9vmrM/bhbwynM+efpgofmue9mzN0x6HmGCmho0GoFz0eS5buyZKmxxxjfg1adKEUqVKMWrUKGxtbV8kCg6Ao8MSn1zjEyhaD+7tgxNJeMrz8gMnT7i9AwK1sRO/WPcRO4BXFkChSnBjI/ybhKc8n+VQoBRcXQ3n5yeOr78Wyvc2uq4K4xRFpP57SwjRBrgJ5FyfkJbkzp3EL6UcyGbnB3RxP4NzlC39bpbAMcqGITdK8tA2Ml4617D8hu3R110ItY5vOaZa6AvbQBOuliHSKr6iqPXkxQDq1MtlEsnhE6J5ScsTY5VkfMNHjsB9o+uVGncjnAiNzpcl3YVdtnblsVcjo9JevXqV/v3706RJE0aNGkWnTp3MK5w5UIoiTQgpk26SGxII0RbYA5RCWz9RCJgipdxofvES4+3tLY8cOWKJos1Oo2GOAPj7PbKoHObku8Pf8eGWD/Es7slG342UsDeRx7JsQGxDMbt2n8Qa8Rs3bhxSSr788ks+iO0TSsjtHdpvcdMMZmf5a5cNzJYLIY5KKb3Tc26q3zZSyk36ZgjQWC/w1fQUpsjdfLTzIz7d+yltXNuwqvMqCuax4MpcY3jnHe33p58sK0cW4Ny5c/Tp04e9e/fSvHlzFixYQNmyZZM/Qe8yMpWiUFiWlBbcWQNd0Gw8bZVSBuqti4+AfEDNzBFRkVOoWrQqg2oPwq+lHzZWWbD/JSE3blhagizD/fv3CQoKYunSpfTs2TPTB/knTszU4hQJSOlpXYLW3XQImCuEuAr4AOOklL9ngmyKHMC9p/c4dusYLSq24B2Pd3jH4x1Li6QwkuPHj+Pv78/w4cOpV68eV69eTdFnhDkx0XIMRTpJSVF4Ax5SyhghhB3aqF5FKeXtzBFNkd05e/8srVe25mH4Q64MvYKDXRaw8aNIlWfPnjFt2jQ+//xzXnrpJfr06UOhQoUspiQAAgK0X09Pi4mQq0nJKGCElNrkdCnlM+CcUhIKY9lzdQ8+S3x48vwJW9/eqpRENuGff/7B09OTTz/9lJ49exIYGEihQoUsLRbDhmlBYRlSalFUFkKc1LcFUEHfF4CUUuYO11+KNLPy1EreXf8u5RzLsfntzZR3Km9pkdKHj4+lJchUHj58SIsWLShSpAjbtm2jefPm6c/slQWmE0xhcVJSFMrnhCJdBNwOwMfFh9+6/oZzPmdLi5N+Pv3U0hJkCkePHqVWrVo4OzuzceNGateunXFfEYWUrY2cREpGAZUhQIXRREZHci3kGhWcKzCr6SyiYqLIY53H0mIpUuDhw4eMGDGCZcuW8fvvv9OhQwcaN25smsxv6MusXJQ1v5yAWecoCiFaorlRtQYWSylnJZGmEeAH2AL3pZQNzSmTwvSEPAuh8y+dOX33NP8O/pdCeQvlDCURu+L4118tK4cZ+PXXXxk0aBAPHjxgwoQJtGjRwrQFxJrWSEZRREZGcuPGDZ49e2ZUdpMna79BQaYQzgwUzjoC2tnZ4eLiEt+cSgYxm6LQ12HMA5qh+do+LITYIKU8EyeNI/Ad0FJKeU0IUcxc8ijMw7WQa7Re0ZqzD86yuN1iCuW1/MCnyXjwwNISmIUBAwbw/fffU6tWLbZu3YqnBaYS3bhxA3t7e8qWLWvUmoxSpbRfS3pPTZHH+rwgC3e5SSl58OABN27coFy5cibL1yhFIYTIB5SWUp5NQ96vABeklJf0PFYBHYAzcdJ0B36TUl4DkFLeTUP+Cgtz9OZR2v7clvDIcLa+vZUm5ZtYWiRFMkgpiYmJwdrammbNmlG2bFlGjhyJjY1lFj4+e/bMaCUBWVhBZDGEEBQuXJh790xr4DtVn9lCiHZAALBV3/cUQmwwIu+SwPU4+zf0Y3FxA5yEEP5CiKNCiJ5GSa3IEny691PyWudlX599SklkYS5fvkzz5s356quvAHjzzTcZO3asxZRELGlZ3R0amivsZZoEc6yaT1VRAFPQWgePAKSUAUBZI85LStqEFghtAC+gDdACmCSEcEuUkRD9hBBHhBBHTK0pFWknLFIzq/2/Dv/jwPsHqFq0qoUlUiRFdHQ0c+fOpVq1ahw4cABHR0dLi5Ru/vtPCwrLYIyiiJIygcF847iBZgIkFhc0E+UJ02yVUj6VUt4HdgM1EmYkpVwopfSWUnoXLVo0HaIoTEGMjGHktpE0XNqQsMgw7PPaU7xgxl1oZlmaNNFCNuTff/+lQYMGDB06lNdee43Tp0/Tt2/fzBPAZ7kWsijXr1+nXLlyPHz4ENDcuJYrV46rV7XJnufPn6dt27ZUqFABLy8vGjduzO7dmk+TpUuXUrRoUTw9PXF3d6dz586EhYUnW1ZcwsLCaNOmDZUrV8bd3Z1x48YZ4p4/f07Xrl2pWLEiderU4cqVKwCcPXsWLy8vatSowf79+wGIioqiadOmhCX0hWImjGl7BgohugPWQghXYAiwz4jzDgOuQohywH9AN7QxibisB74VQtgAeYA6wNfGCq8wkuvXoUePxMdHjtScEZ89+8KFWFwmTtSM7AQEIIcNpUeVf1lZ/C4f3ihJ3hWt4JNPoV492LcPPkrCAY2fn2ZzYccOmDEjcfyCBZpvy40b4cskHNAsX66NYq5eDfOTcECzdi0UKQJLl2ohIZs3a06GvvsO1qxJHB9rs3r2bNi0KX5cvnywZQsA06fDzp3xowsXfjEZavx40J9fAy4uL4zODhummaCINUPRqJHm92jhQm2/Xz/N/1FcPD21yweaEduE9gl9fF4s8+jUKfG4u6trMBcuXGD58uX89NPb9OwZv4Hfti2MGvVCnraVF9K04kpDfIhjFxq+P5Cwx2GcW9iahIQW6039nr15cPM+11d2ThQfVnIA9Xy7Jnvrxf7dz57B1SQm4r/8MhQqpPmEun5d+82fP3G69FKqVCkGDBjAuHHjWLhwIePGjaNfv36UKVOGZ8+e0aZNG2bPnk379u0BCAwM5MiRI7z22msAdO3alW+//RaA7t27s/q3zbz7jnF+OUaNGkXjxo2JiIigSZMmbNmyhVatWrFkyRKcnJy4cOECq1atYuzYsaxevZoFCxYwa9YsypYty7hx4/j111+ZP38+PXr0IL8pL0oKGKMoPgQmAM+BlcA2IImnPj5SyighxGA9vTXwg5TytBCivx7/vZQySAixFTgJxKBNoQ1MX1UUiVi9WvutVy/DWW0q/ICVxe/y8eUyTL1SNsP5KUzPkyfHePTob0qVGknp0j5cuXKF/Pnzs2JF6uc2rbiSioUDuPDA0+xyJqToJ8OwCwqIdyxPXsAa8sZAKX0GrY0t2iR6Y4iraZNh+PDheHl54efnx969e/nmm28AWLFiBT4+PgYlAVCtWjWqVauWKI+oqCiePn2Kk6NmoubOnTv079+fS5cuATB//nzqxXn+8ufPb1irkidPHmrVqsUN/Stg/fr1TJkyBYDOnTszePBgpJTY2toSHh5OWFgYtra2PHr0iI0bN7Jt2zYyC2McF9WUUh7PJHlSRTkuSkuGjbTfDHp7eR71nGrzq2FjZcPJ/iextTbd/OysTKtW2q/esMgw5nK+Ex4eztSpU5k9ezbFixfnzJkzabfPlMmOd4KCgqhSRTf+ENvkMiVGKAqAbdu20bJlS7Zv306zZs0AGDFiBGXKlGHo0KFJnrN06VJGjx5NyZIluXXrFm5ubvhvWIC1tTVd+36Mj48Pw4YNIzo6mtDQUBwckrZz9ujRI2rVqsWOHTsoX7481apVY+vWrbi4aA5EK1SowMGDBwkLC6Nnz548f/6cBQsWsHTpUjp06EDDhskvOYt3fXXM6rgI+EoI8TLwC7BKSnk6PQUpsi/3w+5TrEAxPn7t41yjJADCjet2tii7d+/m/fff5/z58/Tp04fZs2enz4ifJT2zGfFCNxdbtmzh5ZdfJjAw0KAoEtKxY0fOnz+Pm5sbv/32G/Ci60lKyaBBg/hizhLGjejHX3/9xY8//giAtbV1skoiKioKX19fhgwZQvnymi20pD7ahRCULl0af/3r4sKFC9y8eZPKlSvTo0cPIiIimD59Om5uieYAmZRUB7OllI2BRsA9YKEQ4pQQQrkRyUWULFSSve/upUVFE6/eVWSIhw8f0rp1a6KiotixYweLFy/O1jObMpuAgAD+/PNPDhw4wNdff82tW7cAcHd359ixY4Z069atY+nSpYaB77gIIWjXrh2796Wtl6Nfv364uroyLI5JXBcXF65f11YUREVFERISgrNzfFtpEyZMYPr06cydO5e3336bqVOnMnXq1DSVnR6MmfWElPK2lHIu0B9tTcXH5hRKkXVYGrCU26G3M92jmSJ5Dh8+jJQSZ2dnNm3axKlTp2iS0dlZQbO1kEuQUjJgwAD8/PwoXbo0o0ePZpQ+ut+9e3f++ecfNmx4sVwspdlFe/fupUI5bYJnkyZNmK9PvIiOjubx48eJ0k+cOJGQkBD8ErSk2rdvz7JlywBYu3Ytr7/+erznbteuXZQsWRJXV1fCwsKwsrLC2to6c2Y+SSlTDGhWZKcAgcAuYABQLLXzzBW8vLxkTqXhUAfZcKiDCTNsqIV0cuS/I1JMEXLM9jEmEyk7kcHLZ/L87t+/L3v06CEBuW7dOhNJpfNnQy1kEmfOnMm0spJiwYIFskuXLob9qKgoWatWLenv7y+llDIoKEi2atVKlitXTtatW1c2a9ZM/vnnn1JKKf/3v//JIkWKyBo1asjq1avLVq1ayTsX/pEy5F95+/Zt2b59e1mtWjVZo0YNuW/fvnjlXr9+XQKycuXKskaNGrJGjRpy0aJFUkopw8PDZefOnWWFChVk7dq15cWLFw3nxcTEyKZNm8qHDx9KKbXrV7NmTVm9enW5d+/eRPVL6voCR2Q637vGDGYfAH4GfpFSJlwHkemowew0cP++9lukSJpPlVLS4H8NOPfgHOc/PJ8rHQ/N1j+wY6eRZpT0DmZLKfnll18YPHgwwcHBfPTRR3z00UfkzZvXNIKBZQezcwKPdetGWcS8eqYPZksp66YnY0UWIB0KIpbVp1fzz/V/WNRuUa5UEmA6BZFRPvjgAxYtWoS3tzc7duzAw0P5DFNkLskqCiHEGillFyHEKeKb3lAe7rILsYvQevdO02lhkWGM+XMMNYvX5F3Pd00uliJ1ZBwjfq1atcLNzY1hw4ZZ3D6TIneS0l0XO4m4bWYIojAD6VQU4ZHhvFbmNT7w+gBrK2uTi5VdMNe6h9S4dOkSffv2pUWLFowZM4aOHTuav1DrfOYvQ5FtSXbWk5Tylr45UEp5NW4ABmaOeApLUDh/YX568ycalGlgaVFyFdHR0Xz99ddUr16dw4cPUyQDXYdppvEWLSgUSWDM9NikVqG0MrUgiqzBrL2zOHnnpKXFyHUEBQXx6quvMmLECBo3bsyZM2d47733LC2WQgGkPEYxAK3lUF4IEffNYQ/8Y27BFJnP3mt7Gb9zPGGRYXi8pIagMpNHjx5x+fJlVqxYga+vb+avWzk1XfutPilzy1VkC1JqUawE2gEb9N/Y4CWlfCcTZFNkIjEyhqFbh1LSviRjXx1raXFyBYcPH2a2PgfXx0cz4te9e3fLLG68s1MLuYiZM2fi7u6Oh4cHnp6eHDx4kClTpjB+/Ph46QICAgxTTcuWLUuDBvG7ZD09PalWN7Fv8ICAAHx8fAxlrI410onmTKpOnTq4urrStWtXIiIiAM2Xubu7Ow0aNOCBbhL44sWLdOvWzaR1TyspKQoppbwCDAKexAkIIZxTOE+RVdi8WQtGsDRgKcduHePzZp9TIE8BMwuWPejSRQumJiwsjNGjR1O3bl3mzJljWL2bL58aUM4s9u/fz6ZNmzh27BgnT55kx44dlCpVCl9f33gvdIBVq1bRvfsLDwlPnjwxmNoICgpKtoz8+fPz448/cvr0abZu3cqwYcN49OgRAGPHjmX48OGcP38eJycnlixZAsCXX37JgQMH6NmzJytXambfJ06cyPTp001Z/TST0qynlWgzno6iTY+N+5kjgfJmlEthCoy0Vf/4+WPG7xxPvVL18K3ma2ahsg8DzTBl49Ejf2rU6MuFCxfo168fn3/+efqM+OUgLGE89tatWxQpUsSwaDHuxAFHR0cOHjxInTp1AFizZk08k95dunRh9erVjBo1ip9//hlfX1+WL1uSqIy4hvpKlChBsWLFuHfvHg4ODvz1118GRdCrVy+mTJnCgAEDsLKy4vnz54SFhZE3b1727NnDyy+/jKurawauRsZJVlFIKdvqv+UyT5zcTYMAW1qcfUbA0kaGY0edmrC8jNZv/NnJVuSNiW/SdH/htqwupa0M8wtoFC9ux9O6HHBqxf2qDYmOhlOnEpdZvDgULWFDHpcPOHGwHU4j4nd7lCgBxYppDmb+/Tfx+S4u2rq+sLDEzncAypQBJyfN3/GFC4njy5UDBwcICYHLlxPHV6wIBQtCcHDSDm7c3DR9eP9+Yuc+AJUrg50d3L0LN5OwK+DuDra2cPu2FuLi4AClS4O1iWYIv1PpLYYtW0txRyv++rgAjT1+g8P6it7QSxCZwC6QVV5w0FfXPrkAUQmcRlvnh0L6y+jxOYhOYPPHpiDYV9S2Q4Ig5nn8eNtCUFD/3ru7C2wdXqzQNjeFJ8NjvUMjoihE25k2/4hn8Dh5t8nN65Zl2pQLuFUsS9NG9ej6Zisa1n8FAN+OTVn143zqVHHkwOEACjsWwPWlGG31tYykc8ta9B4wnlH92rHx97WsWPwFy5fGpCjOoUOHiIiIoEKFCjx48ABHR0fDmhgXFxf+0/28Tp48mRYtWlCiRAl++uknunTpwqpVq0x0UdJPqqt3hBCvAgFSyqdCiHeAWoCflPKa2aXLZdS+GkX926EEmGgh9CrZjYvBFRP7lk2AdUx+Sl+cxpM7pik3pxASAnfuaMoyIzx+fAB7+zp0q/snrsWgdqWC5M+bxYws5i0CeZwsUrTfrORf6OaiYMECHN31K3v2HeHvPQfp+u4IZk0ZQe+336Rbp9bUa+7LlzPHsurXzfh2bhPvXGcnR5wcHVi19g+qVCpP/nx2IKwgT9I98rdu3aJHjx4sW7YMKyurZM2JAzRr1sxg7nzZsmW0bt2as2fPMnv2bJycnJgzZ06mebWLR2rGoNC8zwk0X9Yn0Rbi7UqvcamMhpxsFNChj5d06GO6+hljhG7I5iFy87nNJitT8YK7d+9KX1/fF0b8fi+rBYXFjQIm5JdffpFt27Y17NevX1/+9ddf0sXFRV6/ft1wvEyZMvLevXty2bJl0tnZWW7YsEFevnxZuru7J5lvSEiIrFmzplyzZo3hWExMjCxcuLCMjIyUUkq5b98+2bx583jnPX36VDZu3FhGRETIRo0ayZCQEDl//ny5cOFCo+pjaqOAxqyjiNIL6QDMkVLOQZsiq8jmbL+4nbmH5nLqbhJ9Uop0I6Xk559/pmrVqqxdu5YpU6bQunVrKFBGCwqLc/bsWc6fP2/YDwgIoEyZF/+Nr68vw4cPp0KFCgaPc3Hp2LEjY8aMoUWL5H20RERE0LFjR3r27Mlbb71lOC6EoHHjxqxduxbQWg4dOnSId+7nn3/O0KFDDW5QhRBYWVlljknxpEhNk6CZFh8PnAeKo/m/PpVezZTRkJNbFF96FJdfehQ3WX4ptSgioiJk1XlVZYU5FeSzyGcmK1Mh5fvvvy8B+corr8hTp069iMhkU95ZGUu3KI4cOSJ9fHxklSpVZPXq1WXHjh3lvXv3DPF3796VNjY2cv78+fHOi21RxCW5FsXy5culjY2NwZx4jRo15PHjx6WUUl68eFHWrl1bVqhQQXbu3Fk+e/biGfzvv/9kmzZtDPtr1qyRVatWlfXq1ZN37941qn6WMDNeHOgOHJZS7hFClAYaSSl/NKP+SpacbGZ878taQ63+rScmyS8lW0XfHPyGIVuHsL7betpXap84gSJNyDhG/NavX8/FixcZOnQo1nFHwtfqfdidE3tKy23kODPjWQxLmBm/LYRYAdQWQrQFDllKSSjSRnLG7B6GP+Rj/49pWr4p7dwSLxRSpI3Yqa4tWrRg7NixiboRDMiUZ8YoFFmVVMcohBBdgEPAW0AX4KAQorO5BVOYD0c7R75q/hV+LfyUi9MMEBUVxZdffomHhwdHjx6lWLFilhZJoTALxhi3nwDUllLeBRBCFAV2AGvNKZgi4yTnoc1KWPFuTeVnIiOcPn2ad999l8OHD9O+fXu+++47SpYsaWmxFAqzYMysJ6tYJaHzwMjzFGnkvwJ5+K9AHpPlt2mTFmKRUvLWL2+x5FjiVaSKtBEaGsr169dZvXo1v//+u1ISihyNMS2KrUKIbWh+swG6AsYZEFKkiQ8aaYvgu5op//Vn17P2zFoalmlophJyNgcPHsTf35+xY8dSp04dLl++jJ1dGlYU5y1sPuEUCjOSastASjkaWAB4oC26WyilVOZFsxnPop4xcvtI3Iu609+7v6XFyVY8ffqUESNG4OPjw7x58wxG/NKkJADyl9KCQpHNSFZRCCFchRDrhRCBaAPZX0oph0sp12WeeLmLTw9c59MD182St98BPy4FX8KvpR82VsrvsrH89ddfeHh48PXXX9O/f38CAwNzvRG/nIK1tbVmIrxaNdq1a2ew7HrlyhXy5cuHp6enIcSaAd+yZQve3t5UqVKFypUrMyrhACCwYsUKPDw88PDwoF69epw4ccIQt3XrVipVqkTFihWZNWuW4fjYsWPx8PCgZ8+ehmPLly9nzpw5Zqp9GklugQWwB+gLVAJGAb+ld7GGKUNOXnC3p3hBuad4QZPl17KlFoLDg2XBTwrKDj93MFneuYH79+/LAgUKSFdXV7lr166MZ7jGQQsKiy+4k1LKAgUKGLZ79uwpZ8yYIaVMfgHdqVOnZPny5WVQUJCUUsrIyEg5b968ROn++ecf+fDhQymllJs3b5avvPKKlFLKqKgoWb58eXnx4kX5/Plz6eHhIU+fPi0fPXok69evL6WUsnv37vLkyZMyLCxMvv766zIiIiJddTP1gruUPi3tpZSL9O2zQohjZtVYCpOzxeAC2ZEN3TZQ2qG0JcXJNuzbtw8fHx8KFy5s+IJUviLMx7Ctwwi4HWDSPD2Le+LX0s/o9D4+Ppw8mbIL4M8//5wJEyZQuXJlAGxsbBiYhC36evXqGbbr1q3LDd2s8aFDh6hYsSLly2sWe7t168b69esZPHgwERERSCkJDw/H1taWL774giFDhmBra2t0HcxJSmMUdkKImkKIWkKIWkC+BPuKbEB0TDQAjcs1poJzBQtLk7W5e/cu3bp149VXX2X9+vUANGjQQCmJHE50dDQ7d+6kffsXFgouXrxo6HYaNGgQAIGBgXh5eaUp7yVLltCqVSsA/vvvP0qVejFGFWte3N7enk6dOlGzZk3KlSuHg4MDhw8fTn7hpgVIqUVxC/gqzv7tOPsSeN1cQilMw7Rpkh/k67zfuBkTX5toaXGyLFJKVqxYwdChQwkNDWX69OmaET9FppCWL39TEh4ejqenJ1euXMHLy8tg3hugQoUKBGTQm9Lff//NkiVL2Lt3L0Bsl348Yhe8jhkzhjFjxgDw/vvvM23aNBYvXsz27dvx8PBg4kTLPr/JtiiklI1TCEpJmIELDnZccDCdA5efT6/kKrspaa/m+KdEnz596NGjB25ubhw/fpyJEyeSJ4/p1rMosib58uUjICCAq1evEhERwbx581JM7+7uztGjR43K++TJk7z//vusX7+ewoW1adEuLi4GF6oAN27coEQCZyfHjx8HNO94P/74I2vWrCEwMDCepVtLoKa/ZCGG1dfMHPc2UX7/ucylQGh1enn2MlGOJubCQriiuYOk8khwaad5ETv0QeK01SZC8aYQHABHhyWOr/EJFK0H9/bBiY8Sx3v5gZMn3N4BgTOIiZHESLCxFrxR9j4en47nw9HTsb61GXYk4QPVZzkUKAVXV8P5+Ynj668FuyJwaakWEtJoM+QtmtyVUFgQBwcH5s6dS4cOHRgwYECy6UaPHs2bb75J/fr1cXNzIyYmBj8/P0aMGBEv3bVr13jzzTdZvnx5PHeotWvX5vz581y+fJmSJUuyatUqgzvUWCZNmsTChQuJjIwkOlrrNraoeXEds66wFkK0FEKcFUJcEEKMSyFdbSFEtLIhZVpirMLJF14RK5FFF9JfWam9+DOZczfCaDTqBLN/0b7u2tcrwrCBveJbejUH+UtqQZHlqFmzJjVq1EjR7aiHhwd+fn74+vpSpUoVqlWrxq1btxKlmzZtGg8ePGDgwIF4enri7a0ZbLWxseHbb7+lRYsWVKlShS5duuDu7m447/fff6d27dqUKFECR0dHfHx8qF69OkIIatRIzU+leUnVzHi6MxbCGjgHNANuAIcBXynlmSTS/Qk8A36QUqZoQyonmxlfWln74uz9r2lcQxYc7UG+8Irc+/Y3k+RncmL9Mzf1z5TioqKi+Oqrr5g8eTJ2dnbMnTuXHj16ZErZQKbXNyujzIybl0w3My600Za3gfJSymm6P4riUspDqZz6CnBBSnlJz2cVmpe8MwnSfQj8CtROq/A5jYohz0yan9ujwdhGW8YPclYjMDCQ3r17c/ToUTp27Mi8efN4+eWXLS2WQpEtMGaM4jsgBm2W0zTgCca92EsCcZcZ3wDqxE0ghCgJdNTzTjY/IUQ/oB9A6dJqLYCxHFvUz9IipIzP8kwrKiwsjJs3b/LLL7/QqVMnZV5doUgDxnRe15FSDkLrGkJKGQwYMyUkqScxYT+XHzBWShmdUkZSyoVSSm8ppXfRompA0Fhuh97mfth9S4uRPAVKacFM7N+/32Am4ZVXXuHy5ct07txZKQmFIo0Yoygi9XEECQZ/FMa46roBxH0LuAA3E6TxBlYJIa4AnYHvhBBvGJG3wgg8vmjOq7OycKvi6motmJjQ0FCGDRvGq6++yvfff8+TJ5pr2bx585q8LIUiN2CMopgLrAOKCSFmAnuBT4w47zDgKoQoJ4TIA3QDNsRNIKUsJ6UsK6Usi+YIaaCU8vc0yJ+jOFU4P6cK5zdZfmFh8DAru2c+Pz/pqaYZ4M8//6R69erMmTOHgQMHcurUKezt7U1ahkKR2zDGZ/YKIcRRoAlad9IbUsogI86LEkIMBrYB1mgzmk4LIfrr8d9nTPScx/i6WgMs+ZncipR48OABHTt2pGTJkuzevZsGDRpYWiSFIkdgjM/s0kAYsBGtRfBUP5YqUsrNUko3KWUFKeVM/dj3SSkJKWXv1KbGKhRJsWfPHqSUFC5cmG3bthEQEKCUhCJVChYsmOjYlClTKFmyJJ6enlStWpWff/45iTPhq6++omrVqnh4eNCkSROuXr1qiFu2bBmurq64urqybNkyw/G3334bDw8PPvroxYLQ6dOnG+yKZWWM6Xr6A9ik/+4ELgFbUjxDkS4W+F9mgf9lS4uRbbh9+zadO3fmtddeMzxsr776qjLip8gQw4cPJyAggPXr1/PBBx8QGRmZKE3NmjU5cuQIJ0+epHPnzgY7TQ8fPmTq1KkcPHiQQ4cOMXXqVIKDgw2WaU+ePMmePXsICQnh1q1bHDp0KEsZ/0sOY7qeqsfd1y3HJmFjQZFRSj6NMGl+NULHYBvjYNI8swJSSn788UeGDx9OWFgYn3zyCW3atLG0WIr0cnSY6VfoO3lqZlsygKurK/nz5yc4OJhixYrFi2vcuLFhu27duvz0008AbNu2jWbNmuHs7AxAs2bN2Lp1K56enoSHhxMTE0NERATW1tZ8/PHHTJs2LUMyZhZptvUkpTwmhMj1i+OyA//Mf8fSIqRM/fT1NL733nssXbqUV199lcWLFxv8AygUpuTYsWO4uromUhIJMcaUuK+vL6VLl6ZWrVr06NGDCxcuIKWkZs2aZq2DqTBmZXZci1dWQC3ANDYmFGbl4sOL5LHOQymHLOqn2a6I0UljYmKIiYnBxsaGN998Ey8vLwYOHIiVVRa1Y6Uwngx++Zuar7/+mkWLFnHp0iW2bt2aYtqffvqJI0eOsGvXLiBlU+J+fn6GY+3atWPBggXMnDmTEydO0KxZM/r27Wu6SpgYY54y+zghL9pYRdbvVFNQ5+uONP58qKXFSJ7kLK0m4OzZszRs2JDPP/8c0B6ywYMHKyWhMAvDhw/n7NmzrF69mp49e/LsWdKmdXbs2MHMmTPZsGGDYY2OMabE169fj7e3N0+fPiUwMJA1a9awfPlyi1uITYkUnzR9oV1BKeVUPcyUUq6QUprWKJECgEPFCnKoWOKZGOnl2TMICTFZdqYnFUURGRnJrFmzqFGjBqdPn1bmWxSZyptvvom3t3e8mUuxHD9+nA8++IANGzbE65pq0aIF27dvJzg4mODgYLZv306LFi0M8ZGRkcyZM4fRo0cTFhZmaG3Ejl1kVZLtehJC2OhrIZTb00xiWm3NBPWIVNLlBk6dOkWvXr04fvw4nTt35ptvvqF48eKWFkuRgwgLC8PFxcWwn9CvBMDHH39M9+7d6du3b7wW7OjRowkNDeWtt94CNBt0GzZswNnZmUmTJlG7dm3D+bED2wDz5s2jV69e5M+fHw8PD6SUVK9endatW+Po6GimmmaclMYoDqGNRwQIITYAvwBPYyOllFnUdnXyLPR7h5VXNllajGQJLRpNwXuVABg/Hvbvjx/v4gL65AqGDYOEnhrd3GDhQm27Xz8IzwPZdaJoeHg4d+/e5ddff+XNN9+0tDiKHEhMTOqWiLy8vDh79myi4zt27Ej2nPfee4/33nsvybhhw4YZtoUQya7TyGoYM+vJGXiAZuFVoq3OlkC2UxQrr2wiIF8InuFZc8roK3NXYBWdDxabJr98+cClsGnyygz27t3Lrl27mDBhAq+88goXL15U9pkUiixASoqimD7jKZAXCiIW83g7ygQ8wx3w93tkaTGSxPvbAMP2p5+mnDbOBIokWbgQWgZNoVDeQhmWy9w8efKE8ePHM2/ePMqVK8eQIUOwt7dXSkKhyCKkpCisgYIYZy5ckQV5s0oW77JptJlt2/+kX7VqXL9+nSFDhjBz5swkTSsoFArLkZKiuCWlzB7LBhVJcvLOSexs7HAr7JZ6YgvwICScTl3eplSpUuzdu5d69epZWiSFQpEEKU2PVd5dsjnv/PYO43aMs7QYidi1a5dmxO/Bav5c0p+AgAClJBSKLExKiqJJpkmhAMDF/hEu9o8sLYbZuHXrFp06daJRo0aaEb9ra/ApfESNRSgUWZxkFYWUMiu7vMmRPKrRiEc1GllaDJMjpeR///sfVatW5Y8//mDWrFm0bdvW0mIpcjHXr1+nXLlyPNQ9ewUHB1OuXDmDufDz58/Ttm1bKlSogJeXF40bN2b37t0ALF26lKJFi+Lp6Ym7uzudO3dO16rq9u3bU61aNcP+8+fP6dq1KxUrVqROnTpcuXIF0CwTeHl5UaNGDfbrc+ajoqJo2rRppq3mVjYQFGand+/evPfee1SvXp2TJ08yduxYbGzSbI9SoTAZpUqVYsCAAYwbp3XNjhs3jn79+lGmTBmePXtGmzZt6NevHxcvXuTo0aN88803XLp0yXB+165dCQgI4PTp0+TJk4fVq9Pm0ve3335LNGljyZIlODk5ceHCBYYPH87YsWMBWLBgAbNmzWLt2rXMnj0bgPnz59OjRw/y5zedR8yUUE9rFuL5P4f1rexvnDc6OhopJTY2Nrz11lvUqVOH/v37K/tMiqRp1CjxsS5dYOBAzadv69aJ43v31sL9+9C5c/w4f/9Uixw+fDheXl74+fmxd+9evvnmGwBWrFiBj48P7du3N6StVq1avK//WKKionj69ClOTk4A3Llzh/79+xuUyvz58xONv4WGhvLVV1+xcOFCunTpYji+fv16pkyZAkDnzp0ZPHgwUkpsbW0JDw8nLCwMW1tbHj16xMaNG9m2bVuqdTQVSlFkISKlrUnz+6LZFxTMk/lTTYOCgujTpw9t2rRhwoQJqptJkSWxtbXliy++oGXLlmzfvp08efIAcPr0aWrVStly0erVq9m7dy+3bt3Czc2Ndu3aATBkyBAaNmzIunXriI6OJjQ0NNG5kyZNYuTIkYlaA3FNlNvY2ODg4MCDBw8YNGgQPXv25Pnz5yxYsIBp06YxYcIEg52ozEApihxMi4otUk9kQiIjI/n888+ZNm0a9vb2fPjhhymf0NQ/U+RSZANSagHkz59yfJEiRrUgkmLLli28/PLLBAYG0qxZsyTTdOzYkfPnz+Pm5sZvv2kGKbp27cq3336LlJJBgwbxxRdfMG7cOP766y9+/PFHAKytrXFwiG8FIiAggAsXLvD1118bxiBiSc5EeenSpfHX63fhwgVu3rxJ5cqV6dGjBxEREUyfPh03N/NOgVf9ADmYAzcOcOL2iUwp68SJE3h7ezNx4kQ6duzImTNn8PX1zZSyFYr0EBAQwJ9//smBAwf4+uuvuXXrFgDu7u4cO3bMkG7dunUsXbrUMPAdFyEE7dq1Mwx0p8b+/fs5evQoZcuWpX79+pw7d45GerdbXBPlUVFRhISExDMoCDBhwgSmT5/O3Llzefvtt5k6dSpTp05NT/XThFIUOZh+G/sxdZf5byLQWhPBwcH8/vvvrFq1KlWvYAAEzdaCQpHJSCkZMGAAfn5+lC5dmtGjRzNq1CgAunfvzj///MOGDRsM6VOaXbR3714qVKgAQJMmTZg/fz6gjdM9fvw4XtoBAwZw8+ZNrly5wt69e3FzczO0Ftq3b28wab527Vpef/31eN1Lu3btomTJkri6uhIWFoaVlRXW1taZMvNJdT1lIUo7PLK0CGli9+7d7Nq1i0mTJuHt7c2FCxcM/bxG8Z9uybfKKPMIqFAkw6JFiyhdurShu2ngwIEsXbqUXbt20bBhQzZt2sSIESMYNmwYL730Evb29kycONFwfuwYRUxMDC4uLixduhSAOXPm0K9fP5YsWYK1tTXz58/Hx8fHKJn69OlDjx49qFixIs7OzqxatcoQJ6VkxowZrFmzBoB+/frx9ttvExUVZVBM5kQk1S+WlfH29pZHjhxJ17mNhjkCZFmjgLETP9LZ3ZoIj/keVHSuyG9dTWvo9/Hjx4wbN4758+dTvnx5AgICsLe3T3tGOxppv7llrCK31TcFgoKCqFKliqXFyLEkdX2FEEellN7pyU91PSnSxJYtW6hWrRrff/89w4YN4+TJk+lTEgqFItugup6yEKF7A/QtTwtKkTwPHjygS5culC5dmn379lG3bl1Li6RQKDIBpShyMN+1+Y78thlbuSml5O+//6Zx48YULlyYHTt24OnpaRr7TNbZ1f+eQpG7UF1POZj6petT6+X0uzy/efMmHTt2pEmTJpoRP6BOnTqmM+LXeIsWFApFlkYpihzMX5f/4uCNg2k+T0rJ4sWLqVq1Ktu2bWP27NlqdbVCkYtRXU85mGFbh6Vr1lPPnj356aefaNiwIYsXL6ZixYrmEfDUdO23+iTz5K9QKEyCalFkIco6h1DWOcQiZUdHRxMZGQlAt27dWLBgAX/99Zf5lATAnZ1aUCgswMyZM3F3d8fDwwNPT08OHjzIlClTGD9+fLx0AQEBhqmmZcuWpUGDBvHiPT09kzQYGMvjx48pWbIkgwcPNhy7fPkyderUwdXVla5duxIREQHAr7/+iru7Ow0aNODBgwcAXLx4kW7dupmkzulFKYosxP2qDblftWGml3v69GleffVVPvvsMwCDiWVl6VWRU9m/fz+bNm3i2LFjnDx5kh07dlCqVCl8fX0TmQxftWoV3bt3N+w/efLEYGojKCgo1bImTZpEw4bxn+uxY8cyfPhwzp8/j5OTE0uWLAHgyy+/5MCBA/Ts2ZOVK1cCMHHiRKZPn56h+mYU9SbIQthEhGETkTmOSAAiIiKYNm0aNWvW5OLFi7i6umZa2QpFXBo1Shy++06LCwtLOl5fDM39+4njUuPWrVsUKVLEMDGjSJEilChRgkqVKuHo6MjBgy/G9tasWRPvi75Lly4GZfLzzz+naNPs6NGj3Llzh+bNmxuOSSn566+/6KybRu/Vqxe///47AFZWVjx//txgUnzPnj28/PLLFn82zaoohBAthRBnhRAXhBCJnDcLId4WQpzUwz4hRA1zypPVeXToHI8OncuUsgICAvD29mby5Ml07tyZM2fO0LVr10wpW6GwNM2bN+f69eu4ubkxcOBAdu3aZYjz9fU1mM84cOAAhQsXjvei7ty5s8GK7MaNGw0mxhMSExPDyJEj+eKLL+Idf/DgAY6OjgbnXS4uLvz3338ATJ48mRYtWrBjxw58fX2ZMWMGkyZZfgzPbIPZQghrYB7QDLgBHBZCbJBSnomT7DLQUEoZLIRoBSwE6phLptzG0jeWks8m6bUKsdYpN2zYkOyNbnbyFrZMuYosR2ZbGS9YsCBHjx5lz549/P3333Tt2pVZs2bRu3dvunXrRr169fjyyy9ZtWpVohaDs7MzTk5OrFq1iipVqiTrZe67776jdevWBh8TsSRnThygWbNmBvtTy5Yto3Xr1pw9e5bZs2fj5OTEnDlzMs2rXVzMOevpFeCClPISgBBiFdABMCgKKeW+OOkPAC5mlCfXkXANhb+/P7t27WLy5MkGI362tqZ1lpQmGvxqubIVuR5ra2saNWpEo0aNqF69OsuWLaN3796UKlWKsmXLsmvXLn799VeDn+q4dO3alUGDBhmMASbF/v372bNnD9999x2hoaFERERQsGBBPv30Ux49ekRUVBQ2NjbcuHGDEiVKxDs3LCyMZcuWsW3bNpo3b8769etZuXIlK1asoG/fvqa+FKlizq6nksD1OPs39GPJ0QdIcvWVEKKfEOKIEOLIvXv3TChizmbj2Y34X/EnJCSEDz74gMaNG/PTTz/x5MkTAMsqCYXCgpw9e5bz588b9gMCAihTpoxh39fXl+HDh1OhQgVcXBJ/v3bs2JExY8bQokXyzsFWrFjBtWvXuHLlCrNnz6Znz57MmjULIQSNGzdm7dq1gNZy6NChQ7xzP//8c4YOHWpwgyqEwMrKKlNMiieFOVsUSfnpS9JUrRCiMZqiqJ9UvJRyIVq3FN7e3tnL3K0FmfDXBApcLsC1Fde4ffs2o0aNYurUqRZpuiZJgD4N0fNTy8qhyHWEhoby4Ycf8ujRI2xsbKhYsSILFy40xL/11lsMHTrU4Ec7Ifb29owdOzbd5X/22Wd069aNiRMnUrNmTfr06WOIu3nzJkeOHDH4zx45ciR169bF0dHRMOid2ZhTUdwA4nbOuQA3EyYSQngAi4FWUsoHZpQny1OuaGL/uhkhKjSKI98coXLFyvz+++/Url3bpPlnmPuJm/QKRWbg5eXFvn37ko0vWrSoYV1RXBK6LwVtbUVgYGCK5fXu3ZvevXsb9suXL8+hQ4eSTFuiRAk2bdpk2H/rrbd46623Uszf3Jiz6+kw4CqEKCeEyAN0AzbETSCEKA38BvSQUmbOdJ8szL1K9blXKclGldFIKdmxYwdSSmwK2lB/Un2OHj2a9ZSEQqHINphNUUgpo4DBwDYgCFgjpTwthOgvhOivJ/sYKAx8J4QIEEKkzyNRDsEu7AF2YelvVN24cYP27dvTrFkzgxE/pwpOafM6p1AoFAkwq60nKeVmYHOCY9/H2X4feN+cMmQn7h+LHftP27TRmJgYFi9ezOjRo4mMjOSrr76iXbt2fLzwY9MLqVAoch25yijgrYjC3IlwMmrlprEEB8PVq4mPu7lp87/v34cbNxLHV64MdnZw9y7c1EduYmLKUyPvyRcuM42k56wgVuy8y+uejiwaUZ3yL6+Hv9ezpqQdea3+S3N+yRJ+E57dBau84KC7WXxyAaISjK1Y54dCbtr243MQnWCmhk1BsK8IIbr5A1PJl9UJDgAnT0tLoVCkmVylKO5EOBEanXWd5dTIe5K3HX8yKm1UtERKia2NFd0bF6ORhyN9WhU3LNwBqGzq2U3P7mpKIY+J/FE45DKfyU6eULZ7qskUiqxGrlIUAAWtw9O8ijM5AgK0X09P0+RHDd3nQ9NHKSY7efIkffr0oX379kyaNInWTZNOtzpwNYXyFqKVayvTyBf75d/U3zT5KRSKbIEyCpgBhg3TQmbx/PlzJk+ejJeXF1evXjWYPk6OmXtmsujYokySTqHIXlhbWxtMhLdr145Hjx4B2hTYfPny4enpaQixZsC3bNmCt7c3VapUoXLlyowaNSrZ/A8fPoy1tbVhYR3A1q1bqVSpEhUrVmTWrFmG42PHjsXDw4OePXsaji1fvpw5c+aYuNbpQymKrES7ElpIgmPHjlGrVi2mTZtGt27dCAoKMlifzDSK+GhBocgB5MuXj4CAAAIDA3F2dmbevHmGuAoVKhAQEGAIefLkITAwkMGDB/PTTz8RFBREYGAg5cuXTzLv6Ohoxo4dG2/ldnR0NIMGDWLLli2cOXOGn3/+mTNnzhASEsK+ffs4efIk0dHRnDp1ivDwcJYuXcrAgQPNfh2MIdd1PWVpGhVLMTo8PJw//viD1q1bZ5JACVArqBVmotHSRomOdXHvwsDaAwmLDKP1isT3fG/P3vT27M39sPt0XhP/o8m/t3+ayvfx8eHkyZMppvn888+ZMGEClStXBsDGxibZF/k333xDp06dOHz4sOHYoUOHqFixokG5dOvWjfXr1zN48GAiIiKQUhIeHo6trS1ffPEFQ4YMyTJmdlSLIitx95kWdHbu3MnkyZMBqFWrFufOnbOcklAocijR0dHs3LmT9u3bG45dvHjR0O00aNAgAAIDA/Hy8ko1v//++49169bRv3//RMfjWpKNNS9ub29Pp06dqFmzJuXKlcPBwYHDhw8nsv9kSVSLIivx2b8APGr9iNGjR7N48WLc3NwYNWoU9vb2Bvv1FmNPJ+1XWX1VmJiUWgD5bfOnGF8kf5E0tyBAa6F7enpy5coVvLy8DOa94UXXU3oYNmwYn332GdbW1vGOp2RefMyYMYwZMwaA999/n2nTprF48WK2b9+Oh4cHEydOTJcspkIpigzwySemz3N9SCQDqlblzp07jBkzhilTppAvX/qm9P7R/Q9srU3YdH2eq01xKXIYsWMUISEhtG3blnnz5jFkyJBk07u7u3P06FFq1EjZv9qRI0cMHvHu37/P5s2bsbGxwcXFxeBCFUjSvPjx48cBcHNzY+jQoezevZtu3bpx/vx5i3q5U4oiA9SrZ9r87kfF8M71MMpXq8iGDRvw9vbOUH6lHEqlnkihyOU4ODgwd+5cOnTowIABA5JNN3r0aN58803q16+Pm5sbMTEx+Pn5MWLEiHjpLl++bNju3bs3bdu25Y033iAqKorz589z+fJlSpYsyapVqwx+sWOZNGkSCxcuJDIykujoaACLmhePRY1RZIB9+7SQEaSUbNu2DSklRWys+Lt8AY4cOZJhJQHww/EfWBe0LsP5KBQ5nZo1a1KjRg2DC9Sk8PDwwM/PD19fX6pUqUK1atW4deuW0WXY2Njw7bff0qJFC6pUqUKXLl1wd3c3xMdaeC5RogSOjo74+PhQvXp1hBCptmLMjUiq3ywr4+3tLY8cSZ/tQMf3tZfvo8WmsT0YawokvQv4rl27Rv/+/dmyZQvr1q3jjcm9tYgTjzIuHOAx34OKzhX5retvJslPLbhTmIqgoKBU1wEp0k9S11cIcVRKma4vUNX1ZAFiYmL4/vvvGTt2LFJK5s6dq/mtPpXFPcG+1MTSEigUCgugFIUFePvtt1m1ahXNmjVj4cKFlC1bVovwKWJRuVKl+iRLS6BQKCyAUhSZRFRUlGbEz9aWXr160bx5c3r37h3PiB/XLTtgpVAoFEmhBrMzgRMnTlCnTh0+/VRb2dyyZUvefffd+EoCwO+cFrIqf7fSgkKhyFWoFkUG8PNLOf7Zs2fMmDGDzz77DGdn53gzHDKDv3v9jY2VCf/i6HDT5aVQKLINSlFkADf3MKJjogF77ofd53Lwi/nTQSeDmDxkMlcuXKFXr16Mnz6ex1aPOfzf4Xh5VH+pOnY2dtx6cosbTlHawThpPIt7Ymtty43HN7j1JPFUPK8SXlgJK66FXONO6J14cfls81GtWDXTVVihUORKcpWi8PJvysNrbWi0NsBwbECvMLrOqcf1gzfp0eJuonNGfhhBu+mvcHbLJT7wfRwv7lzzj3nPsx4zPhrHlp3f0/NYnMHem8ADmDdjBAMnfMl3q0cx6N8vE+V/oekGKrzajh9/ncS4xk+1g4tfMcTfGXWHYgWK8f2R75m5Z2ai88M+CiOfbT6+2v8Vcw7GN0n8RTlXrteaRKtqPeDSUi0kpNFmsMkP576Da2sSx8dOhQ2arTy0KXIUBQsWJDQ0vnfGKVOmsGjRIooWLUpERASTJk3C19c32TzWrl3LW2+9xeHDhw1rn5YtW8aMGTMAmDhxIr169QK0SSynTp2ibdu2fKKbdZg+fToeHh5Zyq5TUuQqRfHwWhsuRVanJldMkl9knqf879kSZjCOxkVqM+3PMpy+H0YP95cAiG4oaVhfMzPcuogPm04m/rov3kab6dS58GtU+/ln8HCEvgsN8Q55HQDo4dEDH5fEJr7zWOcBoG+tvjQr3yxeXN1/x5Ev7ADQI8N1BZSHNkWuYPjw4YwaNYrz58/j5eVF586dk7Ti+uTJE+bOnUudOnUMxx4+fMjUqVM5cuQIQgi8vLxo3769wXTHyZMnadCgASEhIYSFhXHo0CEmTcr6swlzl6JoPwlHwH+tf6K4UnVK4P8oaV8QAJValcf/Ufxjb6524MLDfAQHBzNp4SqW/nOVypUrs2jpPuzt7eOlLdukE2WbdEo2/wrtelIh3w/ajlubxOUXqUSlIpWSPd+9mDvuxRKMgVz7Ah6f1rbL99ZCcrgN1EJyVBmlBYXCHCTlN710F+2ejAoD/ySsJsfe08/uw94EvllMsCjU1dWV/PnzExwcTLFiiV0ATJo0iTFjxjB79mzDsW3bttGsWTOcnZ0BaNasGVu3bsXT05Pw8HBiYmKIiIjA2tqajz/+mGnTpmVYzswgV816CnEMJcQxNPWEacnzeAhVq1Zl+fLljB8/nuPHjydSEgqFIvtx7NgxXF1dk1QSx48f5/r167Rt2zbe8eRMiVepUoXSpUtTq1YtunTpwoULF5BSUrNmTbPXwxTkqhZFrT2NTJrf88fPufHjDTyqeLB58+Zs86crFFmOlFoANvlTjrcrYlKzMl9//TWLFi3i0qVLbN26NVF8TEwMw4cPZ+nSpYniUjIl7hdnmmS7du1YsGABM2fO5MSJEzRr1oy+ffuarA6mJle1KIIvdyD4csYGjaSUbNmyBSklhYsUpvrY6hw6dEgpCYUihzB8+HDOnj3L6tWr6dmzJ8+ePYsX/+TJEwIDA2nUqBFly5blwIEDtG/fniNHjhhlSnz9+vV4e3vz9OlTAgMDWbNmDcuXL7e4hdiUyFWKIqNcvXqVVq1a0bp1azZs2MCPHX8kYGpAlnFXmAjXAVpQKBRp5s0338Tb25tly5bFO+7g4MD9+/e5cuUKV65coW7duga3AC1atGD79u0EBwcTHBzM9u3b4/nNjoyMZM6cOYwePZqwsDBDayN27CKrkqu6ntJLTEwM3333HePGjQPg22+/1Yz4ZXXKdLW0BApFliUsLAwXlxeGOBP6lQD4+OOP6d69O3379sXKKvXvamdnZyZNmkTt2rUN58cObAPMmzePXr16kT9/fjw8PJBSUr16dVq3bo2jo2PGK2UmcpWZ8Zp59gBwPKJBms7z9fVl1apVtGjRggULFlCmTBkAvvjnC26F3uKrFl+lS55EmNqM91O9CVxAOTBSZC2UmXHzosyMZxKRkZFIKcmTJw+9e/emZcuW9OzZM559pv039nPh4QULSpkK+/X1E8p/hEKhyAC5SlHc6jJW30rZLd2xY8fo06cPHTp0YMqUKfH6GBUKhSK3kasGs5/ZRfDMLvkBo/DwcMaPH88rr7zC7du38fT0zDzhFIpcRnbr9s4umOO65qoWhddfybcMDh8+zDvvvMO5c+d47733mD17Nk5OTpkonUKRe7Czs+PBgwcULlw4sbl9RbqRUvLgwQPs7OxMmm+uUhQPb7RMNs7GxgYpJX/++SdNmzY1Kr+i+YvyNPKpqcRTKHINLi4u3Lhxg3v37llalByHnZ1dvNlcpiBXKYqEbNu2jd27dzNz5kxq1qxJUFAQ1tbWRp+/oN0CM0pnAiqPtLQECkWS2NraUq5cOUuLoTASs45RCCFaCiHOCiEuCCHGJREvhBBz9fiTQoha5pQnlocPH9KrVy9atmzJunXrePLkCUCalES2wKWdFhQKhSIDmE1RCCGsgXlAK6Aq4CuEqJogWSvAVQ/9gPnmkge0/rtHMf5UqVKFlStXMnHixAwZ8Zu2axr9N/U3sZQm5PFZLSgUCkUGMGfX0yvABSnlJQAhxCqgA3AmTpoOwI9SG6Y/IIRwFEK8LKVM7MrNBNhYB3NXfEypfDBrAlQsNYNDP83gXExB+pTzAhnNgev/EJlg1sB5WYj3ytaEmEj+ubGfGD2+oYQC1lawaTfYFYPoZ/D438QF53eBvEU0c8lPkvCJXaAM5HGCh0dBWCc2uVzjEyhaD+7tgxMfJT7fy0/zFXF7BwTOeHE81tGQWkehUCgygNlWZgshOgMtpZTv6/s9gDpSysFx0mwCZkkp9+r7O4GxUsojCfLqh9biAKgEZOQzuQhwPwPnZ3dU/XNv/XNz3UHVv5KUMl3dJ+ZsUSQ15y2hVjImDVLKhcDCJNKmXSghjqR3GXtOQNU/99Y/N9cdVP2FEOmzfYR5B7NvAHGNDLmgeZJOaxqFQqFQWBBzKorDgKsQopwQIg/QDdiQIM0GoKc++6kuEGKu8QmFQqFQpA+zdT1JKaOEEIOBbYA18IOU8rQQor8e/z2wGWgNXADCgHfNJU8cTNKFlY1R9c+95Oa6g6p/uuuf7cyMKxQKhSJzyVVGARUKhUKRdpSiUCgUCkWK5FhFkVXNh2QWRtT/bb3eJ4UQ+4QQNSwhpzlIre5x0tUWQkTra35yDMbUXwjRSAgRIIQ4LYTYldkymhMj7n0HIcRGIcQJvf6ZMTaaKQghfhBC3BVCBCYTn773npQyxwW0wfOLQHkgD3ACqJogTWtgC9pajrrAQUvLncn1rwc46dutckr9jal7nHR/oU2o6GxpuTP5v3dEs5BQWt8vZmm5M7n+HwGf6dtFgYdAHkvLbqL6vwbUAgKTiU/Xey+ntigM5kOklBFArPmQuBjMh0gpDwCOQoiXM1tQM5Fq/aWU+6SUwfruAbQ1LDkBY/57gA+BX4G7mSlcJmBM/bsDv0kprwFIKXPSNTCm/hKwF5ojjIJoiiIqc8U0D1LK3Wj1SY50vfdyqqIoCVyPs39DP5bWNNmVtNatD9pXRk4g1boLIUoCHYHvM1GuzMKY/94NcBJC+AshjgohemaadObHmPp/C1RBW9x7ChgqpYzJHPEsTrreeznVH4XJzIdkU4yumxCiMZqiqG9WiTIPY+ruh2ZTLDoHelczpv42gBfQBMgH7BdCHJBSJmGxMtthTP1bAAHA60AF4E8hxB4p5WMzy5YVSNd7L6cqitxuPsSougkhPIDFQCsp5YNMks3cGFN3b2CVriSKAK2FEFFSyt8zRULzYuy9f19K+RR4KoTYDdQAcoKiMKb+76IZI5XABSHEZaAycChzRLQo6Xrv5dSup9xuPiTV+gshSgO/AT1yyJdkLKnWXUpZTkpZVkpZFlgLDMwhSgKMu/fXAw2EEDZCiPxAHSAok+U0F8bU/xpaawohxEtoFqkvZaqUliNd770c2aKQWdd8SKZgZP0/BgoD3+lf1lEyB1jWNLLuORZj6i+lDBJCbAVOAjHAYillktMpsxtG/v/TgaVCiFNoXTFjpZQ5wvy4EOJnoBFQRAhxA5gM2ELG3nvKhIdCoVAoUiSndj0pFAqFwkQoRaFQKBSKFFGKQqFQKBQpohSFQqFQKFJEKQqFQqFQpIhSFIosiW7VNSBOKJtC2lATlLdUCHFZL+uYEMInHXksFkJU1bc/ShC3L6My6vnEXpdA3QKqYyrpPYUQrU1RtiL3oqbHKrIkQohQKWVBU6dNIY+lwCYp5VohRHNgtpTSIwP5ZVim1PIVQiwDzkkpZ6aQvjfgLaUcbGpZFLkH1aJQZAuEEAWFEDv1r/1TQohEFmGFEC8LIXbH+eJuoB9vLoTYr5/7ixAitRf4bqCifu4IPa9AIcQw/VgBIcQfuj+DQCFEV/24vxDCWwgxC8iny7FCjwvVf1fH/cLXWzKdhBDWQogvhBCHheYn4AMjLst+dINuQohXhOZX5Lj+W0lfmTwN6KrL0lWX/Qe9nONJXUeFIhGWtp+uggpJBSAazXBbALAOzYpAIT2uCNrK0tgWcaj+OxKYoG9bA/Z62t1AAf34WODjJMpbiu6XAngLOIhmOO8UUADNHPVpoCbQCVgU51wH/dcf7evdIFOcNLEydgSW6dt50Cx55gP6ARP143mBI0C5JOQMjVO/X4CW+n4hwEbfbgr8qm/3Br6Nc/4nwDv6tiOafacClv6/VcjaIUea8FDkCMKllJ6xO0IIW+ATIcRraGYnSgIvAbfjnHMY+EFP+7uUMkAI0RCoCvyjmyrJg/YlnhRfCCEmAvfQLOo2AdZJzXgeQojfgAbAVmC2EOIztO6qPWmo1xZgrhAiL9AS2C2lDNe7uzzEC297DoArcDnB+fmEEAFAWeAo8Gec9MuEEK5o1kBtkym/OdBeCDFK37cDSpNzbD0pzIBSFIrswtto3si8pJSRQograC85A1LK3boiaQMsF0J8AQQDf0opfY0oY7SUcm3sjhCiaVKJpJTnhBBeaDZzPhVCbJdSTjOmElLKZ0IIfzRT112Bn2OLAz6UUm5LJYtwKaWnEMIB2AQMAuai2S/6W0rZUR/490/mfAF0klKeNUZehQLUGIUi++AA3NWVRGOgTMIEQogyeppFwBI0l5AHgFeFELFjDvmFEG5GlrkbeEM/pwBat9EeIUQJIExK+RMwWy8nIZF6yyYpVqEZY2uAZrwO/XdA7DlCCDe9zCSRUoYAQ4BR+jkOwH96dO84SZ+gdcHFsg34UOjNKyFEzeTKUChiUYpCkV1YAXgLIY6gtS7+TSJNIyBACHEcbRxhjpTyHtqL82chxEk0xVHZmAKllMfQxi4OoY1ZLJZSHgeqA4f0LqAJwIwkTl8InIwdzE7AdjTfxjuk5q4TNL8gZ4BjQohAYAGptPh1WU6gmdL+HK118w/a+EUsfwNVYwez0Voetrpsgfq+QpEianqsQqFQKFJEtSgUCoVCkSJKUSgUCoUiRZSiUCgUCkWKKEWhUCgUihRRikKhUCgUKaIUhUKhUChSRCkKhUKhUKTI/wHYlU6EcZ0RUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_tests = np.array([y_test_20,y_test_20,y_test_20,y_test_20,y_test_40,y_test_40,y_test_40,y_test_40])\n",
    "y_preds = np.array([XGBc_y_predicted_20,SVM_y_predicted_20,RFc_y_predicted_20,LR_y_predicted_20,XGBc_y_predicted_40,SVM_y_predicted_40,RFc_y_predicted_40,LR_y_predicted_40])\n",
    "models_name=np.array(['XGBc 20%','SVM 20%','RFC 20%','LR 20%','XGBc 40%','SVM 40%','RFC 40%','LR 40%'])\n",
    "title = 'ROC curve of simple models with split 80/20 and 60/40'\n",
    "roc(y_tests,y_preds,models_name,title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e3d52",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning XGBoost classifier using Evolutionary Computation\n",
    "\n",
    "title = Hyperparameter tuning in XGBoost using genetic algorithm,\n",
    "\n",
    "year = 2018,\n",
    "\n",
    "url = https://towardsdatascience.com/hyperparameter-tuning-in-xgboost-using-genetic-algorithm-17bd2e581b17,\n",
    "\n",
    "author = Mohit Jain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c85ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(723)\n",
    "np.random.seed(723)\n",
    "\n",
    "def initilialize_poplulation(numberOfParents):\n",
    "    learningRate = np.empty([numberOfParents, 1])\n",
    "    nEstimators = np.empty([numberOfParents, 1], dtype = np.uint8)\n",
    "    maxDepth = np.empty([numberOfParents, 1], dtype = np.uint8)\n",
    "    minChildWeight = np.empty([numberOfParents, 1])\n",
    "    gammaValue = np.empty([numberOfParents, 1])\n",
    "    subSample = np.empty([numberOfParents, 1])\n",
    "    colSampleByTree =  np.empty([numberOfParents, 1])\n",
    "\n",
    "    for i in range(numberOfParents):\n",
    "        learningRate[i] = round(random.uniform(0.01, 1), 2)\n",
    "        nEstimators[i] = random.randrange(10, 1500, step = 25)\n",
    "        maxDepth[i] = int(random.randrange(1, 10, step= 1))\n",
    "        minChildWeight[i] = round(random.uniform(0.01, 10.0), 2)\n",
    "        gammaValue[i] = round(random.uniform(0.01, 10.0), 2)\n",
    "        subSample[i] = round(random.uniform(0.01, 1.0), 2)\n",
    "        colSampleByTree[i] = round(random.uniform(0.01, 1.0), 2)\n",
    "    \n",
    "    population = np.concatenate((learningRate, nEstimators, maxDepth, minChildWeight, gammaValue, subSample, colSampleByTree), axis= 1)\n",
    "    return population\n",
    "\n",
    "   \n",
    "\n",
    "def fitness_accuracy_score(y_true, y_pred):\n",
    "    fitness = round((accuracy_score(y_true, y_pred)), 4)\n",
    "    return fitness\n",
    "\n",
    "def train_population(population, dMatrixTrain, dMatrixtest, y_test):\n",
    "    aScore = []\n",
    "    for i in range(population.shape[0]):\n",
    "        param = { 'objective':'binary:logistic',\n",
    "              'learning_rate': population[i][0],\n",
    "              'n_estimators': population[i][1], \n",
    "              'max_depth': int(population[i][2]), \n",
    "              'min_child_weight': population[i][3],\n",
    "              'gamma': population[i][4], \n",
    "              'subsample': population[i][5],\n",
    "              'colsample_bytree': population[i][6],\n",
    "              'seed': 24}\n",
    "        num_round = 100\n",
    "        xgbT = xgb.train(param, dMatrixTrain, num_round)\n",
    "        preds = xgbT.predict(dMatrixtest)\n",
    "        preds = preds>0.5\n",
    "        aScore.append(fitness_accuracy_score(y_test, preds))\n",
    "    return aScore\n",
    "\n",
    "\n",
    "\n",
    "def new_parents_selection(population, fitness, numParents):\n",
    "    selectedParents = np.empty((numParents, population.shape[1])) \n",
    "    \n",
    "    for parentId in range(numParents):\n",
    "        bestFitnessId = np.where(fitness == np.max(fitness))\n",
    "        bestFitnessId  = bestFitnessId[0][0]\n",
    "        selectedParents[parentId, :] = population[bestFitnessId, :]\n",
    "        fitness[bestFitnessId] = -1 \n",
    "    return selectedParents\n",
    "        \n",
    "\n",
    "def crossover_uniform(parents, childrenSize):\n",
    "    \n",
    "    crossoverPointIndex = np.arange(0, np.uint8(childrenSize[1]), 1, dtype= np.uint8)\n",
    "    crossoverPointIndex1 = np.random.randint(0, np.uint8(childrenSize[1]), np.uint8(childrenSize[1]/2)) \n",
    "    crossoverPointIndex2 = np.array(list(set(crossoverPointIndex) - set(crossoverPointIndex1))) \n",
    "    \n",
    "    children = np.empty(childrenSize)\n",
    "    \n",
    "    \n",
    "    for i in range(childrenSize[0]):\n",
    "        \n",
    "        parent1_index = i%parents.shape[0]\n",
    "        parent2_index = (i+1)%parents.shape[0]\n",
    "        children[i, crossoverPointIndex1] = parents[parent1_index, crossoverPointIndex1]\n",
    "        children[i, crossoverPointIndex2] = parents[parent2_index, crossoverPointIndex2]\n",
    "    return children\n",
    "    \n",
    "\n",
    "\n",
    "def mutation(crossover, numberOfParameters):\n",
    "\n",
    "    minMaxValue = np.zeros((numberOfParameters, 2))\n",
    "    \n",
    "    minMaxValue[0:] = [0.01, 1.0] \n",
    "    minMaxValue[1, :] = [10, 2000] \n",
    "    minMaxValue[2, :] = [1, 15] \n",
    "    minMaxValue[3, :] = [0, 10.0] \n",
    "    minMaxValue[4, :] = [0.01, 10.0] \n",
    "    minMaxValue[5, :] = [0.01, 1.0] \n",
    "    minMaxValue[6, :] = [0.01, 1.0] \n",
    " \n",
    "    \n",
    "    mutationValue = 0\n",
    "    parameterSelect = np.random.randint(0, 7, 1)\n",
    "    print(parameterSelect)\n",
    "    if parameterSelect == 0: \n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "    if parameterSelect == 1: \n",
    "        mutationValue = np.random.randint(-200, 200, 1)\n",
    "    if parameterSelect == 2:\n",
    "        mutationValue = np.random.randint(-5, 5, 1)\n",
    "    if parameterSelect == 3: \n",
    "        mutationValue = round(np.random.uniform(5, 5), 2)\n",
    "    if parameterSelect == 4: \n",
    "        mutationValue = round(np.random.uniform(-2, 2), 2)\n",
    "    if parameterSelect == 5: \n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "    if parameterSelect == 6: \n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "  \n",
    "    \n",
    "    for idx in range(crossover.shape[0]):\n",
    "        crossover[idx, parameterSelect] = crossover[idx, parameterSelect] + mutationValue\n",
    "        if(crossover[idx, parameterSelect] > minMaxValue[parameterSelect, 1]):\n",
    "            crossover[idx, parameterSelect] = minMaxValue[parameterSelect, 1]\n",
    "        if(crossover[idx, parameterSelect] < minMaxValue[parameterSelect, 0]):\n",
    "            crossover[idx, parameterSelect] = minMaxValue[parameterSelect, 0]    \n",
    "    return crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f0cfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyp_param_ev_algo(X_train, y_train):\n",
    "    \n",
    "    hyp_X_train, hyp_X_test, hyp_y_train, hyp_y_test = train_test_split(X_train, y_train, test_size = 0.80, random_state = 97,stratify=y_train)\n",
    "\n",
    "    xgDMatrix = xgb.DMatrix(hyp_X_train, hyp_y_train) \n",
    "    xgbDMatrixTest = xgb.DMatrix(hyp_X_test, hyp_y_test)\n",
    "\n",
    "    numberOfParents = 100 \n",
    "    numberOfParentsMating = int(numberOfParents/2)\n",
    "    numberOfParameters = 7 \n",
    "    numberOfGenerations = 5\n",
    "\n",
    "    populationSize = (numberOfParents, numberOfParameters)\n",
    "    population = initilialize_poplulation(numberOfParents)\n",
    "\n",
    "    fitnessHistory = np.empty([numberOfGenerations+1, numberOfParents])\n",
    "    populationHistory = np.empty([(numberOfGenerations+1)*numberOfParents, numberOfParameters])\n",
    "    populationHistory[0:numberOfParents, :] = population\n",
    "\n",
    "    for generation in range(numberOfGenerations):\n",
    "        \n",
    "        fitnessValue = train_population(population=population, dMatrixTrain=xgDMatrix, dMatrixtest=xgbDMatrixTest, y_test=hyp_y_test)\n",
    "        fitnessHistory[generation, :] = fitnessValue\n",
    "\n",
    "        print('Best Iteration',generation ,'Accuracy on train set = {}'.format(np.max(fitnessHistory[generation, :])))\n",
    "\n",
    "        parents = new_parents_selection(population=population, fitness=fitnessValue, numParents=numberOfParentsMating)\n",
    "        children = crossover_uniform(parents=parents, childrenSize=(populationSize[0] - parents.shape[0], numberOfParameters))\n",
    "        children_mutated = mutation(children, numberOfParameters)\n",
    "\n",
    "        population[0:parents.shape[0], :] = parents \n",
    "        population[parents.shape[0]:, :] = children_mutated \n",
    "\n",
    "        populationHistory[(generation+1)*numberOfParents : (generation+1)*numberOfParents+ numberOfParents , :] = population \n",
    "\n",
    "    fitness = train_population(population=population, dMatrixTrain=xgDMatrix, dMatrixtest=xgbDMatrixTest, y_test=hyp_y_test)\n",
    "    fitnessHistory[generation+1, :] = fitness\n",
    "\n",
    "    bestFitnessIndex = np.where(fitness == np.max(fitness))[0][0]\n",
    "\n",
    "    print(\"Best fitness is =\", fitness[bestFitnessIndex])\n",
    "\n",
    "\n",
    "    print(\"Best parameters are:\")\n",
    "    print('learning_rate', population[bestFitnessIndex][0])\n",
    "    print('n_estimators', population[bestFitnessIndex][1])\n",
    "    print('max_depth', int(population[bestFitnessIndex][2])) \n",
    "    print('min_child_weight', population[bestFitnessIndex][3])\n",
    "    print('gamma', population[bestFitnessIndex][4])\n",
    "    print('subsample', population[bestFitnessIndex][5])\n",
    "    print('colsample_bytree', population[bestFitnessIndex][6])\n",
    "    \n",
    "    return population[bestFitnessIndex][0],population[bestFitnessIndex][1],population[bestFitnessIndex][2],population[bestFitnessIndex][3],population[bestFitnessIndex][4],population[bestFitnessIndex][5],population[bestFitnessIndex][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa068d",
   "metadata": {},
   "source": [
    "### BACKWARD ORDER) First RFE, then tuning hyperparameters on selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eacc83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) RFE:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#test tuning XGB hyperparameters with selected features from RFE\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1) RFE:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m newX_train,newX_test \u001b[38;5;241m=\u001b[39m \u001b[43mrfe_xgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test_20\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msimple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2) XGB with RFE features:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m XGB_class(newX_train,newX_test,y_train_20,y_test_20,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,simple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mrfe_xgb\u001b[1;34m(X_train, y_train, X_test, learning_rate, n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree, simple)\u001b[0m\n\u001b[0;32m      8\u001b[0m     clf \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(learning_rate \u001b[38;5;241m=\u001b[39m learning_rate, n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_estimators), max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(max_depth), \n\u001b[0;32m      9\u001b[0m                             min_child_weight \u001b[38;5;241m=\u001b[39m min_child_weight, gamma \u001b[38;5;241m=\u001b[39m gamma, subsample \u001b[38;5;241m=\u001b[39m subsample, \n\u001b[0;32m     10\u001b[0m                             colsample_bytree \u001b[38;5;241m=\u001b[39m colsample_bytree, seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24\u001b[39m,eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m,use_label_encoder \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m rfecv \u001b[38;5;241m=\u001b[39m RFECV(estimator\u001b[38;5;241m=\u001b[39mclf,min_features_to_select\u001b[38;5;241m=\u001b[39mmin_features_to_select,step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m\"\u001b[39m,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mrfecv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#keep selected features + check RFE accuracy scores during running\u001b[39;00m\n\u001b[0;32m     15\u001b[0m newX_train \u001b[38;5;241m=\u001b[39m X_train[X_train\u001b[38;5;241m.\u001b[39mcolumns[rfecv\u001b[38;5;241m.\u001b[39msupport_]]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:710\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    707\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    708\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m--> 710\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[0;32m    716\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test tuning XGB hyperparameters with selected features from RFE\n",
    "print('1) RFE:')\n",
    "newX_train,newX_test = rfe_xgb(X_train_20, y_train_20,X_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "print('2) XGB with RFE features:')\n",
    "XGB_class(newX_train,newX_test,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "print('3) XGB with RFE features & Hyperparameter tuning:')\n",
    "learning_rate, n_estimators, max_depth, min_child_weight,gamma, subsample,colsample_bytree = hyp_param_ev_algo(newX_train, y_train_20)\n",
    "XGB_class(newX_train,newX_test,y_train_20,y_test_20,learning_rate, n_estimators, max_depth, min_child_weight,gamma, subsample,colsample_bytree,simple=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe9497",
   "metadata": {},
   "source": [
    "### FORWARD ORDER) First Forward feature selection, then tuning hyperparameters on selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test tuning XGB hyperparameters with selected features from forward selection\n",
    "print('1) Forward feature selection:')\n",
    "fs_best_features = forward_select_XGB(X_train_20.copy(), y_train_20,xgb.XGBClassifier(seed = 24, use_label_encoder =False))\n",
    "newX_train = X_train_20.loc[:,fs_best_features]\n",
    "newX_test = X_test_20[(newX_train.columns) & (X_test_20.columns)]\n",
    "print('We kept',newX_train.shape[1],'features out of the',X_train_20.shape[1])\n",
    "print('2) XGB with forward feature selection')\n",
    "XGB_class(newX_train,newX_test,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "print('3) XGB with forward feature selection & Hyperparameter tuning:')\n",
    "learning_rate, n_estimators, max_depth, min_child_weight,gamma, subsample,colsample_bytree = hyp_param_ev_algo(newX_train, y_train_20)\n",
    "XGB_class(newX_train,newX_test,y_train_20,y_test_20,learning_rate, n_estimators, max_depth, min_child_weight,gamma, subsample,colsample_bytree,simple=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
