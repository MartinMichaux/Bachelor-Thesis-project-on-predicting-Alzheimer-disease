{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a83341",
   "metadata": {},
   "source": [
    "# Build mutliclass classification models where some use RFE selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d435b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)\n",
    "from sklearn.feature_selection import RFECV\n",
    "import random\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import svm, datasets\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29a92679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first column of dataframe\n",
    "def drop_first_col(df):\n",
    "    return df.iloc[: , 1:]\n",
    "\n",
    "X_train_20 = pd.read_csv(\"dataset\\X_train_3_20.csv\")\n",
    "X_test_20 = pd.read_csv(\"dataset\\X_test_3_20.csv\")\n",
    "y_train_20 = pd.read_csv(\"dataset\\y_train_3_20.csv\")\n",
    "y_test_20 = pd.read_csv(\"dataset\\y_test_3_20.csv\")\n",
    "\n",
    "X_train_40 = pd.read_csv(\"dataset\\X_train_3_40.csv\")\n",
    "X_test_40 = pd.read_csv(\"dataset\\X_test_3_40.csv\")\n",
    "y_train_40 = pd.read_csv(\"dataset\\y_train_3_40.csv\")\n",
    "y_test_40 = pd.read_csv(\"dataset\\y_test_3_40.csv\")\n",
    "\n",
    "X_train_20 = drop_first_col(X_train_20)\n",
    "X_test_20 = drop_first_col(X_test_20)\n",
    "y_train_20 = drop_first_col(y_train_20)\n",
    "y_test_20 = drop_first_col(y_test_20)\n",
    "\n",
    "X_train_40 = drop_first_col(X_train_40)\n",
    "X_test_40 = drop_first_col(X_test_40)\n",
    "y_train_40 = drop_first_col(y_train_40)\n",
    "y_test_40 = drop_first_col(y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c6482",
   "metadata": {},
   "source": [
    "## Test on single simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c80bba",
   "metadata": {},
   "source": [
    "### Single XGB Classifier (with no hyperparameters selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc922337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_class(X_train, X_test, y_train, y_test,learning_rate, n_estimators, max_depth,min_child_weight, gamma, subsample, colsample_bytree, simple):\n",
    "    \n",
    "    if simple:\n",
    "        clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False,objective='multi:softproba')\n",
    "    else:\n",
    "        clf = xgb.XGBClassifier(learning_rate = learning_rate, n_estimators = int(n_estimators), max_depth = int(max_depth), \n",
    "                                min_child_weight = min_child_weight, gamma = gamma, subsample = subsample, \n",
    "                                colsample_bytree = colsample_bytree, seed = 24,eval_metric='mlogloss',use_label_encoder =False,objective='multi:softproba')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_predicted))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, y_predicted))\n",
    "    \n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    y_predicted = label_binarize(y_predicted, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"AUC =\",roc_auc)\n",
    "    \n",
    "    return clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c01f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.56      0.50         9\n",
      "           1       0.70      0.70      0.70        10\n",
      "           2       0.50      0.38      0.43         8\n",
      "\n",
      "    accuracy                           0.56        27\n",
      "   macro avg       0.55      0.54      0.54        27\n",
      "weighted avg       0.56      0.56      0.55        27\n",
      "\n",
      "Accuracy: 0.5555555555555556\n",
      "MCC = 0.3305699764271252\n",
      "AUC = {0: 0.6111111111111112, 1: 0.7617647058823529, 2: 0.6085526315789473}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.32      0.30        19\n",
      "           1       0.42      0.55      0.48        20\n",
      "           2       0.43      0.20      0.27        15\n",
      "\n",
      "    accuracy                           0.37        54\n",
      "   macro avg       0.38      0.36      0.35        54\n",
      "weighted avg       0.38      0.37      0.36        54\n",
      "\n",
      "Accuracy: 0.37037037037037035\n",
      "MCC = 0.03047125546029282\n",
      "AUC = {0: 0.44360902255639095, 1: 0.5544117647058824, 2: 0.5487179487179487}\n"
     ]
    }
   ],
   "source": [
    "sXGBc_y_predicted_20 = XGB_class(X_train_20,X_test_20,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "sXGBc_y_predicted_40 = XGB_class(X_train_40,X_test_40,y_train_40,y_test_40,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8885d3",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d2de33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sSVMc(X_train,X_test,y_train,y_test):\n",
    "    clf = svm.SVC(kernel='poly',probability=True).fit(X_train, y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)\n",
    "    sSVM_y_predicted = clf.predict_proba(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    \n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    y_predicted = label_binarize(preds, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"AUC =\",roc_auc)\n",
    "    \n",
    "    return sSVM_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98c7d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.50         9\n",
      "           1       0.71      1.00      0.83        10\n",
      "           2       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.65      0.65      0.63        27\n",
      "weighted avg       0.65      0.67      0.64        27\n",
      "\n",
      "Accuracy: 0.6666666666666666\n",
      "MCC = 0.5046684724839113\n",
      "AUC = {0: 0.6388888888888888, 1: 0.8823529411764706, 2: 0.6973684210526315}\n",
      "Using 40% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.42      0.43        19\n",
      "           1       0.64      0.80      0.71        20\n",
      "           2       0.36      0.27      0.31        15\n",
      "\n",
      "    accuracy                           0.52        54\n",
      "   macro avg       0.48      0.50      0.48        54\n",
      "weighted avg       0.49      0.52      0.50        54\n",
      "\n",
      "Accuracy: 0.5185185185185185\n",
      "MCC = 0.26754502228372407\n",
      "AUC = {0: 0.5676691729323309, 1: 0.7676470588235296, 2: 0.5435897435897435}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "sSVM_y_predicted_20 = sSVMc(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "sSVM_y_predicted_40 = sSVMc(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df80d3c",
   "metadata": {},
   "source": [
    "### Single Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef7c64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sRFC(X_train,X_test,y_train,y_test):\n",
    "    model = RandomForestClassifier().fit(X_train,y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    sRFC_y_predicted = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    \n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    y_predicted = label_binarize(preds, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"AUC =\",roc_auc)\n",
    "    \n",
    "    return sRFC_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a09f5463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.67      0.52         9\n",
      "           1       0.60      0.60      0.60        10\n",
      "           2       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.52        27\n",
      "   macro avg       0.57      0.51      0.50        27\n",
      "weighted avg       0.56      0.52      0.50        27\n",
      "\n",
      "Accuracy: 0.5185185185185185\n",
      "MCC = 0.2825558872312041\n",
      "AUC = {0: 0.6111111111111112, 1: 0.6823529411764706, 2: 0.5986842105263158}\n",
      "Using 40% as test subset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14464\\1089713667.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14464\\1089713667.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = RandomForestClassifier().fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.21      0.22        19\n",
      "           1       0.45      0.65      0.53        20\n",
      "           2       0.50      0.27      0.35        15\n",
      "\n",
      "    accuracy                           0.39        54\n",
      "   macro avg       0.39      0.38      0.37        54\n",
      "weighted avg       0.39      0.39      0.37        54\n",
      "\n",
      "Accuracy: 0.3888888888888889\n",
      "MCC = 0.06088744506236035\n",
      "AUC = {0: 0.4195488721804511, 1: 0.5897058823529412, 2: 0.582051282051282}\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "sRFC_y_predicted_20 = sRFC(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "sRFC_y_predicted420 = sRFC(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40b2a8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b88a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sLR(X_train,X_test,y_train,y_test):\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs').fit(X_train,y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    sLR_y_predicted = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, preds))\n",
    "    \n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    y_predicted = label_binarize(preds, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"AUC =\",roc_auc)\n",
    "    \n",
    "    return sLR_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c49ed00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.50         9\n",
      "           1       0.69      0.90      0.78        10\n",
      "           2       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.66      0.66      0.65        27\n",
      "weighted avg       0.66      0.67      0.65        27\n",
      "\n",
      "Accuracy: 0.6666666666666666\n",
      "MCC = 0.5011926315100854\n",
      "AUC = {0: 0.6388888888888888, 1: 0.8323529411764704, 2: 0.7598684210526316}\n",
      "Using 40% as test subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50        19\n",
      "           1       0.63      0.85      0.72        20\n",
      "           2       0.50      0.33      0.40        15\n",
      "\n",
      "    accuracy                           0.57        54\n",
      "   macro avg       0.55      0.55      0.54        54\n",
      "weighted avg       0.56      0.57      0.55        54\n",
      "\n",
      "Accuracy: 0.5740740740740741\n",
      "MCC = 0.35483623400235725\n",
      "AUC = {0: 0.6225563909774436, 1: 0.7779411764705882, 2: 0.6025641025641025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "print('Using 20% as test subset:')\n",
    "sLR_y_predicted_20 = sLR(X_train_20,X_test_20,y_train_20,y_test_20)\n",
    "print('Using 40% as test subset:')\n",
    "sLR_y_predicted_40 = sLR(X_train_40,X_test_40,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4956197",
   "metadata": {},
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d95a1d",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "abc872ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_xgb(X_train, y_train,X_test,learning_rate, n_estimators, max_depth,min_child_weight, gamma, subsample, colsample_bytree, simple):\n",
    "    min_features_to_select = 1\n",
    "    \n",
    "    #run RFE on current train subset\n",
    "    if simple:\n",
    "        clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False)\n",
    "    else:\n",
    "        clf = xgb.XGBClassifier(learning_rate = learning_rate, n_estimators = int(n_estimators), max_depth = int(max_depth), \n",
    "                                min_child_weight = min_child_weight, gamma = gamma, subsample = subsample, \n",
    "                                colsample_bytree = colsample_bytree, seed = 24,eval_metric='mlogloss',use_label_encoder =False)\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train)\n",
    "    \n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train.shape[1])\n",
    "    \n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67631c6e",
   "metadata": {},
   "source": [
    "### Test on single XGB classifier using RFE selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5c5e9b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.56      0.48         9\n",
      "           1       0.43      0.30      0.35        10\n",
      "           2       0.38      0.38      0.38         8\n",
      "\n",
      "    accuracy                           0.41        27\n",
      "   macro avg       0.41      0.41      0.40        27\n",
      "weighted avg       0.41      0.41      0.40        27\n",
      "\n",
      "Accuracy: 0.4074074074074074\n",
      "MCC = 0.11507182723729042\n",
      "AUC = {0: 0.5833333333333334, 1: 0.5323529411764706, 2: 0.555921052631579}\n"
     ]
    }
   ],
   "source": [
    "#test rfe then simple XGB classifier\n",
    "# newX_train,newX_test = rfe_xgb(X_train_20, y_train_20,X_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "RFE_XGB_y_predicted = XGB_class(newX_train,newX_test,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19de70",
   "metadata": {},
   "source": [
    "### Test on single SVM classifier using RFE selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "323f2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_SVM(X_train, y_train,X_test):\n",
    "    min_features_to_select = 1\n",
    "\n",
    "    #run RFE on current train subset\n",
    "    clf = SVC(kernel='linear',probability=True) \n",
    "\n",
    "    rfecv = RFECV(estimator=clf,min_features_to_select=min_features_to_select,step=3,n_jobs=-1,scoring=\"r2\",cv=5)\n",
    "    rfecv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    #keep selected features + check RFE accuracy scores during running\n",
    "    newX_train = X_train[X_train.columns[rfecv.support_]]\n",
    "    newX_test = X_test[X_test.columns[rfecv.support_]]\n",
    "    print('We kept',newX_train.shape[1],'features out of the',X_train_40.shape[1])\n",
    "\n",
    "    return newX_train,newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43e31359",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [108, 81]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#test rfe then SVM classifier\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# newX_train,newX_test = rfe_SVM(X_train_40, y_train_40,X_test_40)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m RFE_SVM_y_predicted \u001b[38;5;241m=\u001b[39m \u001b[43msSVMc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnewX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_40\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test_40\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36msSVMc\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msSVMc\u001b[39m(X_train,X_test,y_train,y_test):\n\u001b[0;32m      2\u001b[0m     clf \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m,probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[1;32m----> 3\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m     preds \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      5\u001b[0m     sSVM_y_predicted \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:981\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    964\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    965\u001b[0m     X,\n\u001b[0;32m    966\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    977\u001b[0m )\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[1;32m--> 981\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [108, 81]"
     ]
    }
   ],
   "source": [
    "#test rfe then SVM classifier\n",
    "newX_train,newX_test = rfe_SVM(X_train_40, y_train_40,X_test_40)\n",
    "RFE_SVM_y_predicted = sSVMc(newX_train,newX_test,y_train_40,y_test_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f8f54",
   "metadata": {},
   "source": [
    "### Plot AUC-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4444b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_row(y_test,y_predicted,title):\n",
    "    y_test = label_binarize(y_test, classes=np.arange(3))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    labels=['slow','rapid','stable']\n",
    "    colors = cycle(['blue', 'red', 'green'])\n",
    "    for i, color in zip(range(3), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(labels[i], roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "124c27d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = 'ROC curve of each class of RFE & XGBc'\n",
    "single_row(y_test_20,RFE_XGB_y_predicted,title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c794a8",
   "metadata": {},
   "source": [
    "### FORWARD ORDER using foward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e9e9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_select(X_train, y_train):\n",
    "    \n",
    "    acc_imp = 0  \n",
    "    last_best_acc=1000\n",
    "    features_selected=[]\n",
    "    best_features = []\n",
    "    no_imp_counter=0\n",
    "    \n",
    "    while no_imp_counter<10:\n",
    "        accuracies = []\n",
    "        for i in range(len(X_train)):   \n",
    "            curr_X_train = X_train.iloc[:,i]\n",
    "            for j in range(len(features_selected)):\n",
    "                curr_X_train = pd.concat([curr_X_train, features_selected[j]],axis=1)\n",
    "            fs_X_train, fs_X_test, fs_y_train, fs_y_test = train_test_split(curr_X_train, y_train, test_size = 0.80, random_state = 97,stratify=y_train)\n",
    "\n",
    "            clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False,objective='multi:softproba')\n",
    "            clf.fit(fs_X_train, fs_y_train)\n",
    "            y_predicted = clf.predict_proba(fs_X_test)\n",
    "            accuracies.append(log_loss(fs_y_test, y_predicted))\n",
    "        \n",
    "        best_feature_idx=np.argmin(accuracies) \n",
    "        print('new best feature added =',X_train.iloc[:,best_feature_idx].name)\n",
    "        features_selected.append(X_train.iloc[:,best_feature_idx])\n",
    "        X_train.drop(X_train.columns[best_feature_idx],axis=1,inplace=True)\n",
    "        \n",
    "        curr_acc=accuracies[best_feature_idx]\n",
    "        print('new log loss =',curr_acc)\n",
    "        if curr_acc<last_best_acc:\n",
    "            acc_imp = last_best_acc-curr_acc\n",
    "            last_best_acc = curr_acc\n",
    "            best_features=features_selected.copy()\n",
    "            no_imp_counter=0\n",
    "            print('improvement of',acc_imp,'\\n')\n",
    "        else:\n",
    "            no_imp_counter+=1\n",
    "            print('no improvement for',no_imp_counter,'times \\n')\n",
    "\n",
    "    \n",
    "    print('-> last best log loss on training set =',last_best_acc)\n",
    "    \n",
    "    best_features_names = []\n",
    "    for i in best_features:\n",
    "        best_features_names.append(i.name)\n",
    "\n",
    "    return best_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c510970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Forward feature selection:\n",
      "new best feature added = CATD.YSQAVPAVTEGPIPEVLK\n",
      "new log loss = 1.342066453534296\n",
      "improvement of 998.6579335464658 \n",
      "\n",
      "new best feature added = CNTN2.IIVQAQPEWLK\n",
      "new log loss = 1.2342850686232933\n",
      "improvement of 0.10778138491100275 \n",
      "\n",
      "new best feature added = CFAB.YGLVTYATYPK\n",
      "new log loss = 1.1350263081191259\n",
      "improvement of 0.09925876050416749 \n",
      "\n",
      "new best feature added = CNDP1.ALEQDLPVNIK\n",
      "new log loss = 1.0735944995078548\n",
      "improvement of 0.061431808611271066 \n",
      "\n",
      "new best feature added = CMGA.SGELEQEEER\n",
      "new log loss = 1.0482630591368538\n",
      "improvement of 0.02533144037100099 \n",
      "\n",
      "new best feature added = AATC.LALGDDSPALK\n",
      "new log loss = 1.0662149140803978\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = CH3L1.VTIDSSYDIAK\n",
      "new log loss = 1.0158008875689288\n",
      "improvement of 0.03246217156792497 \n",
      "\n",
      "new best feature added = CMGA.SGEATDGARPQALPEPMQESK\n",
      "new log loss = 1.0111668634003605\n",
      "improvement of 0.004634024168568285 \n",
      "\n",
      "new best feature added = CO4A.VTASDPLDTLGSEGALSPGGVASLLR\n",
      "new log loss = 1.014022954450599\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = CFAB.VSEADSSNADWVTK\n",
      "new log loss = 0.9913987107146746\n",
      "improvement of 0.01976815268568599 \n",
      "\n",
      "new best feature added = CFAB.DAQYAPGYDK\n",
      "new log loss = 0.9787879970738258\n",
      "improvement of 0.012610713640848759 \n",
      "\n",
      "new best feature added = CO2.HAIILLTDGK\n",
      "new log loss = 0.9930693525606873\n",
      "no improvement for 1 times \n",
      "\n",
      "new best feature added = CATD.VSTLPAITLK\n",
      "new log loss = 0.9820691237932649\n",
      "no improvement for 2 times \n",
      "\n",
      "new best feature added = CO5.DINYVNPVIK\n",
      "new log loss = 1.0036783114760772\n",
      "no improvement for 3 times \n",
      "\n",
      "new best feature added = AMBP.ETLLQDFR\n",
      "new log loss = 1.012656609945256\n",
      "no improvement for 4 times \n",
      "\n",
      "new best feature added = APOB.SVSLPSLDPASAK\n",
      "new log loss = 0.9962998845068545\n",
      "no improvement for 5 times \n",
      "\n",
      "new best feature added = CD59.AGLQVYNK\n",
      "new log loss = 0.9912922556629811\n",
      "no improvement for 6 times \n",
      "\n",
      "new best feature added = AATC.IVASTLSNPELFEEWTGNVK\n",
      "new log loss = 0.9932466835939678\n",
      "no improvement for 7 times \n",
      "\n",
      "new best feature added = CO4A.GSFEFPVGDAVSK\n",
      "new log loss = 0.9836730389245625\n",
      "no improvement for 8 times \n",
      "\n",
      "new best feature added = CMGA.YPGPQAEGDSEGLSQGLVDR\n",
      "new log loss = 1.0167873970436296\n",
      "no improvement for 9 times \n",
      "\n",
      "new best feature added = CADM3.GNPVPQQYLWEK\n",
      "new log loss = 1.0184149311148916\n",
      "no improvement for 10 times \n",
      "\n",
      "-> last best log loss on training set = 0.9787879970738258\n",
      "We kept 11 features out of the 320\n",
      "2) XGB with forward feature selection\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.22      0.29         9\n",
      "           1       0.53      0.90      0.67        10\n",
      "           2       0.60      0.38      0.46         8\n",
      "\n",
      "    accuracy                           0.52        27\n",
      "   macro avg       0.51      0.50      0.47        27\n",
      "weighted avg       0.51      0.52      0.48        27\n",
      "\n",
      "Accuracy: 0.5185185185185185\n",
      "MCC = 0.2831066867074795\n",
      "AUC = {0: 0.5277777777777778, 1: 0.7147058823529412, 2: 0.6348684210526316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_9576\\48801181.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  newX_test = X_test_20[(newX_train.columns) & (X_test_20.columns)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.07741523, 0.8709729 , 0.05161195],\n",
       "       [0.00276916, 0.99574184, 0.00148902],\n",
       "       [0.23073117, 0.05610691, 0.7131619 ],\n",
       "       [0.1809202 , 0.8127618 , 0.00631799],\n",
       "       [0.03739429, 0.94344795, 0.01915773],\n",
       "       [0.09092507, 0.03416663, 0.8749083 ],\n",
       "       [0.27524674, 0.694701  , 0.03005224],\n",
       "       [0.19705328, 0.7701762 , 0.03277053],\n",
       "       [0.00415837, 0.99288285, 0.00295873],\n",
       "       [0.11400573, 0.5708898 , 0.3151045 ],\n",
       "       [0.93055904, 0.04550513, 0.02393582],\n",
       "       [0.39936224, 0.54645896, 0.05417882],\n",
       "       [0.33129627, 0.34715116, 0.32155254],\n",
       "       [0.8720001 , 0.02459631, 0.10340361],\n",
       "       [0.10097444, 0.799864  , 0.09916153],\n",
       "       [0.90741086, 0.04828534, 0.04430383],\n",
       "       [0.10396583, 0.04069251, 0.8553416 ],\n",
       "       [0.00673943, 0.9173926 , 0.07586793],\n",
       "       [0.4912472 , 0.24791045, 0.2608423 ],\n",
       "       [0.36596793, 0.23632483, 0.39770728],\n",
       "       [0.08006973, 0.8948227 , 0.02510756],\n",
       "       [0.70359486, 0.10454512, 0.19186002],\n",
       "       [0.002789  , 0.9910096 , 0.0062014 ],\n",
       "       [0.04319182, 0.7187138 , 0.23809437],\n",
       "       [0.15037298, 0.84074   , 0.00888704],\n",
       "       [0.4226596 , 0.00807068, 0.5692697 ],\n",
       "       [0.12420566, 0.70692044, 0.16887388]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test tuning XGB hyperparameters with selected features from forward selection\n",
    "print('1) Forward feature selection:')\n",
    "fs_best_features = forward_select(X_train_20.copy(), y_train_20)\n",
    "newX_train = X_train_20.loc[:,fs_best_features]\n",
    "newX_test = X_test_20[(newX_train.columns) & (X_test_20.columns)]\n",
    "print('We kept',newX_train.shape[1],'features out of the',X_train_20.shape[1])\n",
    "print('2) XGB with forward feature selection')\n",
    "XGB_class(newX_train,newX_test,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f179df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
